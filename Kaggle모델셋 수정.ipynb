{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e188479-eeaa-4c79-82ff-3caa851193b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 120\u001b[0m\n\u001b[0;32m    118\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    119\u001b[0m x_train \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mreshape(x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# reshape to 2D\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m x_train_augmented, y_train_augmented \u001b[38;5;241m=\u001b[39m \u001b[43maugment_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# SMOTE 적용 (데이터 불균형 해결)\u001b[39;00m\n\u001b[0;32m    123\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 83\u001b[0m, in \u001b[0;36maugment_data\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     80\u001b[0m augmented_y\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Time warping\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m warped \u001b[38;5;241m=\u001b[39m \u001b[43mtime_warp\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m augmented_x\u001b[38;5;241m.\u001b[39mappend(warped\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m     85\u001b[0m augmented_y\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "Cell \u001b[1;32mIn[4], line 35\u001b[0m, in \u001b[0;36mtime_warp\u001b[1;34m(x, sigma, knot)\u001b[0m\n\u001b[0;32m     33\u001b[0m warp_steps[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     34\u001b[0m warp_steps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 35\u001b[0m warp_steps[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mknot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     36\u001b[0m warper \u001b[38;5;241m=\u001b[39m interp1d(warp_steps, random_warps, bounds_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextrapolate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m warped_steps \u001b[38;5;241m=\u001b[39m warper(orig_steps)\n",
      "File \u001b[1;32mnumpy\\\\random\\\\mtrand.pyx:780\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mnumpy\\\\random\\\\_bounded_integers.pyx:1425\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import regularizers\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv('./원본 데이터/transformed_train.csv')\n",
    "\n",
    "# 라벨 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "data['activity'] = label_encoder.fit_transform(data['activity'])\n",
    "\n",
    "# 데이터 정규화\n",
    "mean = np.mean(data[['x-accl', 'y-accl', 'z-accl']], axis=0)\n",
    "std = np.std(data[['x-accl', 'y-accl', 'z-accl']], axis=0)\n",
    "data[['x-accl', 'y-accl', 'z-accl']] = (data[['x-accl', 'y-accl', 'z-accl']] - mean) / std\n",
    "\n",
    "# 데이터 분할 (7:3 비율로 train/test 분할)\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42, stratify=data['activity'])\n",
    "\n",
    "# 시계열 데이터 증강 함수들\n",
    "def time_warp(x, sigma=0.2, knot=4):\n",
    "    orig_steps = np.arange(x.shape[0])\n",
    "    random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2,))\n",
    "    warp_steps = np.zeros(knot+2)\n",
    "    warp_steps[0] = 0\n",
    "    warp_steps[-1] = x.shape[0] - 1\n",
    "    warp_steps[1:-1] = np.sort(np.random.randint(1, x.shape[0]-1, size=(knot,)))\n",
    "    warper = interp1d(warp_steps, random_warps, bounds_error=False, fill_value='extrapolate')\n",
    "    warped_steps = warper(orig_steps)\n",
    "    return np.interp(orig_steps, warped_steps, x.T).T\n",
    "\n",
    "def magnitude_warp(x, sigma=0.2, knot=4):\n",
    "    orig_steps = np.arange(x.shape[0])\n",
    "    random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2,))\n",
    "    warp_steps = np.zeros(knot+2)\n",
    "    warp_steps[0] = 0\n",
    "    warp_steps[-1] = x.shape[0] - 1\n",
    "    warp_steps[1:-1] = np.sort(np.random.randint(1, x.shape[0]-1, size=(knot,)))\n",
    "    warper = interp1d(warp_steps, random_warps, bounds_error=False, fill_value='extrapolate')\n",
    "    warped_steps = warper(orig_steps)\n",
    "    return x * warped_steps[:, np.newaxis]\n",
    "\n",
    "def window_slice(x, reduce_ratio=0.9):\n",
    "    target_length = int(reduce_ratio * x.shape[0])\n",
    "    if target_length >= x.shape[0]:\n",
    "        return x\n",
    "    starts = np.random.randint(low=0, high=x.shape[0] - target_length + 1)\n",
    "    return x[starts:starts + target_length]\n",
    "\n",
    "def jitter(x, sigma=0.05):\n",
    "    return x + np.random.normal(loc=0., scale=sigma, size=x.shape)\n",
    "\n",
    "def scaling(x, sigma=0.1):\n",
    "    factor = np.random.normal(loc=1., scale=sigma, size=(x.shape[-1],))\n",
    "    return x * factor\n",
    "\n",
    "def rotation(x):\n",
    "    axis = np.random.uniform(low=-1, high=1, size=3)\n",
    "    angle = np.random.uniform(low=-np.pi, high=np.pi)\n",
    "    rot = Rotation.from_rotvec(angle * axis)\n",
    "    return rot.apply(x)\n",
    "\n",
    "\n",
    "def augment_data(x, y):\n",
    "    augmented_x = []\n",
    "    augmented_y = []\n",
    "    for i in range(len(x)):\n",
    "        sample = x[i].reshape(-1, 3)  # reshape to (n_features/3, 3)\n",
    "        label = y[i]\n",
    "        \n",
    "        augmented_x.append(sample.flatten())\n",
    "        augmented_y.append(label)\n",
    "\n",
    "        # Time warping\n",
    "        warped = time_warp(sample)\n",
    "        augmented_x.append(warped.flatten())\n",
    "        augmented_y.append(label)\n",
    "\n",
    "        # Magnitude warping\n",
    "        warped = magnitude_warp(sample)\n",
    "        augmented_x.append(warped.flatten())\n",
    "        augmented_y.append(label)\n",
    "\n",
    "        # Window slicing\n",
    "        sliced = window_slice(sample)\n",
    "        if len(sliced) > 0:\n",
    "            augmented_x.append(sliced.flatten())\n",
    "            augmented_y.append(label)\n",
    "\n",
    "        # Jittering\n",
    "        jittered = jitter(sample)\n",
    "        augmented_x.append(jittered.flatten())\n",
    "        augmented_y.append(label)\n",
    "\n",
    "        # Scaling\n",
    "        scaled = scaling(sample)\n",
    "        augmented_x.append(scaled.flatten())\n",
    "        augmented_y.append(label)\n",
    "\n",
    "        # Rotation\n",
    "        rotated = rotation(sample)\n",
    "        augmented_x.append(rotated.flatten())\n",
    "        augmented_y.append(label)\n",
    "\n",
    "    return np.array(augmented_x), np.array(augmented_y)\n",
    "\n",
    "\n",
    "# 데이터 증강 적용\n",
    "x_train = train_data.iloc[:, 2:].values\n",
    "y_train = train_data['activity'].values\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)  # reshape to 2D\n",
    "x_train_augmented, y_train_augmented = augment_data(x_train, y_train)\n",
    "\n",
    "# SMOTE 적용 (데이터 불균형 해결)\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_augmented, y_train_augmented)\n",
    "\n",
    "# 데이터 세그먼트화 및 라벨링 함수 (-1, TIME_PERIODS, 3)\n",
    "TIME_PERIODS = 80\n",
    "STEP_DISTANCE = 40\n",
    "\n",
    "def data_segments(data, labels):\n",
    "    segments = []\n",
    "    segment_labels = []\n",
    "    for i in range(0, len(data) - TIME_PERIODS, STEP_DISTANCE):\n",
    "        X = data.iloc[i:i + TIME_PERIODS].values\n",
    "        segment_labels.append(labels.iloc[i])\n",
    "        segments.append(X)\n",
    "\n",
    "    return np.array(segments), np.array(segment_labels)\n",
    "\n",
    "x_train, y_train = data_segments(pd.DataFrame(train_data_resampled), pd.Series(train_labels_resampled))\n",
    "x_test, y_test = data_segments(test_data.iloc[:, 2:], test_data['activity'])\n",
    "\n",
    "# 라벨 원-핫 인코딩\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# 1D CNN 모델 생성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(TIME_PERIODS, 3)),\n",
    "    tf.keras.layers.Conv1D(filters=50, kernel_size=11, activation='relu', kernel_regularizer=regularizers.l2(0.05)),\n",
    "    tf.keras.layers.MaxPool1D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv1D(filters=5, kernel_size=5, activation='relu', kernel_regularizer=regularizers.l2(0.05)),\n",
    "    tf.keras.layers.MaxPool1D(),\n",
    "    tf.keras.layers.Dropout(rate=0.7),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=5, activation='softmax', kernel_regularizer=regularizers.l2(0.05))\n",
    "])\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "ret = model.fit(x_train, y_train, epochs=100, batch_size=400, validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "# 모델 평가 및 결과 출력\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=2)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(f'Train Accuracy: {train_acc}')\n",
    "print(f'Test Accuracy: {test_acc}')\n",
    "\n",
    "# 혼동 행렬 및 분류 보고서 출력\n",
    "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
    "y_true = np.argmax(y_test, axis=-1)\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# 학습 곡선 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(ret.history['accuracy'], \"b-\", label=\"train accuracy\")\n",
    "plt.plot(ret.history['val_accuracy'], \"r-\", label=\"val accuracy\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(ret.history['loss'], \"b-\", label=\"train loss\")\n",
    "plt.plot(ret.history['val_loss'], \"r-\", label=\"val loss\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ba185-722a-4506-8874-78983e5f89d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
