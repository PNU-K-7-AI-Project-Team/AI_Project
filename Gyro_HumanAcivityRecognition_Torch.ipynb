{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db525f0-6c14-427e-a125-fc1128ed7ffa",
   "metadata": {},
   "source": [
    "# **1. 필요한 라이브러리 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a68ca507-4dec-444c-a808-a062c5997e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac9204-4112-456c-9256-8917b5416c0a",
   "metadata": {},
   "source": [
    "# **2. 데이터 전처리 및 특징공학**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dca71bf-abba-4734-ad0a-894ec3b84917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:9: DtypeWarning: Columns (11,14,19,22,25,70,73,86,87,89,90,94,97,100) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_ma'] = data[column].rolling(window=window_size).mean().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_std'] = data[column].rolling(window=window_size).std().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_ma'] = data[column].rolling(window=window_size).mean().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_std'] = data[column].rolling(window=window_size).std().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_ma'] = data[column].rolling(window=window_size).mean().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_std'] = data[column].rolling(window=window_size).std().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_deriv'] = data[column].diff().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_deriv'] = data[column].diff().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_deriv'] = data[column].diff().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_energy'] = data[column]**2\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_energy'] = data[column]**2\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_energy'] = data[column]**2\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_peak'] = data[column].rolling(window=5).max().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_crest'] = data[column].max() / (data[column].std() + 1e-10)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_peak'] = data[column].rolling(window=5).max().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_crest'] = data[column].max() / (data[column].std() + 1e-10)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_peak'] = data[column].rolling(window=5).max().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_crest'] = data[column].max() / (data[column].std() + 1e-10)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['xy_angle'] = np.arctan2(data['gyros_forearm_y'], data['gyros_forearm_x'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['xz_angle'] = np.arctan2(data['gyros_forearm_z'], data['gyros_forearm_x'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['yz_angle'] = np.arctan2(data['gyros_forearm_z'], data['gyros_forearm_y'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_mean'] = data[column].mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_std'] = data[column].std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_median'] = data[column].median()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_skew'] = data[column].skew()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_kurtosis'] = data[column].kurtosis()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_mean'] = data[column].mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_std'] = data[column].std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_median'] = data[column].median()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_skew'] = data[column].skew()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_kurtosis'] = data[column].kurtosis()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_mean'] = data[column].mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_std'] = data[column].std()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_median'] = data[column].median()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_skew'] = data[column].skew()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_kurtosis'] = data[column].kurtosis()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_outlier'] = np.abs(zscore(data[column])) > 3\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_outlier'] = np.abs(zscore(data[column])) > 3\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_outlier'] = np.abs(zscore(data[column])) > 3\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_fft_mean'] = np.mean(amplitude_spectrum)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_fft_max'] = np.max(amplitude_spectrum)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_fft_min'] = np.min(amplitude_spectrum)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_fft_mean'] = np.mean(amplitude_spectrum)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_fft_max'] = np.max(amplitude_spectrum)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_fft_min'] = np.min(amplitude_spectrum)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_fft_mean'] = np.mean(amplitude_spectrum)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_fft_max'] = np.max(amplitude_spectrum)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13000\\111947210.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f'{column}_fft_min'] = np.min(amplitude_spectrum)\n"
     ]
    }
   ],
   "source": [
    "# 모든 열을 숫자형으로 변환하는 함수\n",
    "def convert_to_numeric(df):\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')  # 숫자형으로 변환 불가한 데이터는 NaN으로 대체\n",
    "    df = df.dropna(axis=1)  # NaN이 포함된 열은 제거\n",
    "    return df\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    features = data[['gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z']]\n",
    "    labels = data['classe']\n",
    "\n",
    "    # 이동 평균 및 이동 표준 편차 추가\n",
    "    def add_moving_features(data, window_size=5):\n",
    "        for column in ['gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z']:\n",
    "            data[f'{column}_ma'] = data[column].rolling(window=window_size).mean().fillna(0)\n",
    "            data[f'{column}_std'] = data[column].rolling(window=window_size).std().fillna(0)\n",
    "        return data\n",
    "\n",
    "    # 파생 특징 추가\n",
    "    def add_derivative_features(data):\n",
    "        for column in ['gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z']:\n",
    "            data[f'{column}_deriv'] = data[column].diff().fillna(0)\n",
    "        return data\n",
    "\n",
    "    # 에너지 특징 추가\n",
    "    def add_energy_features(data):\n",
    "        for column in ['gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z']:\n",
    "            data[f'{column}_energy'] = data[column]**2\n",
    "        return data\n",
    "\n",
    "    # 피크 및 크레스트 요소 추가\n",
    "    def add_peak_features(data):\n",
    "        for column in ['gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z']:\n",
    "            data[f'{column}_peak'] = data[column].rolling(window=5).max().fillna(0)\n",
    "            data[f'{column}_crest'] = data[column].max() / (data[column].std() + 1e-10)\n",
    "        return data\n",
    "\n",
    "    # 방향성 및 각도 변화 추가\n",
    "    def add_angular_features(data):\n",
    "        data['xy_angle'] = np.arctan2(data['gyros_forearm_y'], data['gyros_forearm_x'])\n",
    "        data['xz_angle'] = np.arctan2(data['gyros_forearm_z'], data['gyros_forearm_x'])\n",
    "        data['yz_angle'] = np.arctan2(data['gyros_forearm_z'], data['gyros_forearm_y'])\n",
    "        return data\n",
    "\n",
    "    # 통계적 특징 추가\n",
    "    def add_statistical_features(data):\n",
    "        for column in ['gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z']:\n",
    "            data[f'{column}_mean'] = data[column].mean()\n",
    "            data[f'{column}_std'] = data[column].std()\n",
    "            data[f'{column}_median'] = data[column].median()\n",
    "            data[f'{column}_skew'] = data[column].skew()\n",
    "            data[f'{column}_kurtosis'] = data[column].kurtosis()\n",
    "        return data\n",
    "\n",
    "    # 이상치 탐지 추가\n",
    "    def add_outlier_features(data):\n",
    "        from scipy.stats import zscore\n",
    "        for column in ['gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z']:\n",
    "            data[f'{column}_outlier'] = np.abs(zscore(data[column])) > 3\n",
    "        return data\n",
    "\n",
    "    # 푸리에 변환 적용\n",
    "    def fourier_transform_features(data, columns):\n",
    "        from scipy.fft import fft\n",
    "        for column in columns:\n",
    "            fft_values = fft(data[column].values)  # 데이터를 numpy 배열로 변환\n",
    "            amplitude_spectrum = np.abs(fft_values)\n",
    "            data[f'{column}_fft_mean'] = np.mean(amplitude_spectrum)\n",
    "            data[f'{column}_fft_max'] = np.max(amplitude_spectrum)\n",
    "            data[f'{column}_fft_min'] = np.min(amplitude_spectrum)\n",
    "        return data\n",
    "\n",
    "    # 모든 특징 공학 기법 적용\n",
    "    features = add_moving_features(features)\n",
    "    features = add_derivative_features(features)\n",
    "    features = add_energy_features(features)\n",
    "    features = add_peak_features(features)\n",
    "    features = add_angular_features(features)\n",
    "    features = add_statistical_features(features)\n",
    "    features = add_outlier_features(features)\n",
    "    features = fourier_transform_features(features, ['gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z'])\n",
    "\n",
    "    # 숫자형으로 변환\n",
    "    features = convert_to_numeric(features)\n",
    "\n",
    "    # 클래스 레이블 인코딩\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "# 데이터 로드\n",
    "training_data_path = './원본 데이터/pml-training.csv'\n",
    "features, labels = load_and_preprocess_data(training_data_path)\n",
    "\n",
    "# Train/Test 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 유형 확인 및 변환\n",
    "x_train = x_train.values.astype(np.float32)\n",
    "x_test = x_test.values.astype(np.float32)\n",
    "\n",
    "# PyTorch TensorDataset 생성\n",
    "train_dataset = TensorDataset(torch.tensor(x_train).float(), torch.tensor(y_train).long())\n",
    "test_dataset = TensorDataset(torch.tensor(x_test).float(), torch.tensor(y_test).long())\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc288cf0-264c-4f4f-b649-dfd91d5464eb",
   "metadata": {},
   "source": [
    "# **3. 데이터셋 준비 및 모델 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20ddecd-2aa1-4a7e-a1c3-4f7df742befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-LSTM 모델 정의\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=1, stride=1)  # 커널 크기 1로 설정\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(10)  # 입력 크기에 따라 동적으로 풀링\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.lstm1 = nn.LSTM(input_size=128, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool(x)\n",
    "        x, _ = self.lstm1(x.transpose(1, 2))  # LSTM expects input as (batch, seq_len, input_size)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = x[:, -1, :]  # Get the output of the last time step\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "input_size = 48  # 실제 feature 수로 설정\n",
    "num_classes = len(set(y_train))  # 클래스 수로 설정\n",
    "model = CNN_LSTM(input_size=input_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f1b0a-e096-46e2-b5ab-41df9fb5c58c",
   "metadata": {},
   "source": [
    "# **4. 모델 학습 및 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02c6d73-fd7a-4e7a-999f-b066e23a64a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.5055, Train Accuracy: 0.3416\n",
      "Epoch 1/100, Test Loss: 1.7098, Test Accuracy: 0.2833\n",
      "Epoch 2/100, Train Loss: 1.4628, Train Accuracy: 0.3681\n",
      "Epoch 2/100, Test Loss: 1.6710, Test Accuracy: 0.1865\n",
      "Epoch 3/100, Train Loss: 1.4479, Train Accuracy: 0.3833\n",
      "Epoch 3/100, Test Loss: 1.6343, Test Accuracy: 0.1783\n",
      "Epoch 4/100, Train Loss: 1.4321, Train Accuracy: 0.3922\n",
      "Epoch 4/100, Test Loss: 1.6113, Test Accuracy: 0.2724\n",
      "Epoch 5/100, Train Loss: 1.4234, Train Accuracy: 0.3986\n",
      "Epoch 5/100, Test Loss: 1.6829, Test Accuracy: 0.1745\n",
      "Epoch 6/100, Train Loss: 1.4113, Train Accuracy: 0.4007\n",
      "Epoch 6/100, Test Loss: 1.6137, Test Accuracy: 0.2731\n",
      "Epoch 7/100, Train Loss: 1.4006, Train Accuracy: 0.4038\n",
      "Epoch 7/100, Test Loss: 1.7866, Test Accuracy: 0.2792\n",
      "Epoch 8/100, Train Loss: 1.3890, Train Accuracy: 0.4128\n",
      "Epoch 8/100, Test Loss: 1.6212, Test Accuracy: 0.2082\n",
      "Epoch 9/100, Train Loss: 1.3851, Train Accuracy: 0.4169\n",
      "Epoch 9/100, Test Loss: 1.8467, Test Accuracy: 0.2833\n",
      "Epoch 10/100, Train Loss: 1.3773, Train Accuracy: 0.4165\n",
      "Epoch 10/100, Test Loss: 1.9639, Test Accuracy: 0.2833\n",
      "Epoch 11/100, Train Loss: 1.3647, Train Accuracy: 0.4213\n",
      "Epoch 11/100, Test Loss: 1.6862, Test Accuracy: 0.1962\n",
      "Epoch 12/100, Train Loss: 1.3624, Train Accuracy: 0.4209\n",
      "Epoch 12/100, Test Loss: 1.7256, Test Accuracy: 0.1809\n",
      "Epoch 13/100, Train Loss: 1.3576, Train Accuracy: 0.4268\n",
      "Epoch 13/100, Test Loss: 1.9908, Test Accuracy: 0.1952\n",
      "Epoch 14/100, Train Loss: 1.3488, Train Accuracy: 0.4308\n",
      "Epoch 14/100, Test Loss: 1.8668, Test Accuracy: 0.2833\n",
      "Epoch 15/100, Train Loss: 1.3431, Train Accuracy: 0.4335\n",
      "Epoch 15/100, Test Loss: 1.9897, Test Accuracy: 0.2833\n",
      "Epoch 16/100, Train Loss: 1.3368, Train Accuracy: 0.4347\n",
      "Epoch 16/100, Test Loss: 1.8743, Test Accuracy: 0.1730\n",
      "Epoch 17/100, Train Loss: 1.3326, Train Accuracy: 0.4375\n",
      "Epoch 17/100, Test Loss: 2.2908, Test Accuracy: 0.2041\n",
      "Epoch 18/100, Train Loss: 1.3304, Train Accuracy: 0.4390\n",
      "Epoch 18/100, Test Loss: 1.8028, Test Accuracy: 0.2833\n",
      "Epoch 19/100, Train Loss: 1.3207, Train Accuracy: 0.4465\n",
      "Epoch 19/100, Test Loss: 1.7890, Test Accuracy: 0.2833\n",
      "Epoch 20/100, Train Loss: 1.3101, Train Accuracy: 0.4539\n",
      "Epoch 20/100, Test Loss: 1.6200, Test Accuracy: 0.2833\n",
      "Epoch 21/100, Train Loss: 1.3100, Train Accuracy: 0.4519\n",
      "Epoch 21/100, Test Loss: 1.6760, Test Accuracy: 0.1817\n",
      "Epoch 22/100, Train Loss: 1.3056, Train Accuracy: 0.4512\n",
      "Epoch 22/100, Test Loss: 1.6328, Test Accuracy: 0.2833\n",
      "Epoch 23/100, Train Loss: 1.2967, Train Accuracy: 0.4559\n",
      "Epoch 23/100, Test Loss: 2.5629, Test Accuracy: 0.2833\n",
      "Epoch 24/100, Train Loss: 1.2926, Train Accuracy: 0.4645\n",
      "Epoch 24/100, Test Loss: 1.7129, Test Accuracy: 0.1771\n",
      "Epoch 25/100, Train Loss: 1.2906, Train Accuracy: 0.4615\n",
      "Epoch 25/100, Test Loss: 1.9224, Test Accuracy: 0.1791\n",
      "Epoch 26/100, Train Loss: 1.2827, Train Accuracy: 0.4639\n",
      "Epoch 26/100, Test Loss: 1.7479, Test Accuracy: 0.1712\n",
      "Epoch 27/100, Train Loss: 1.2839, Train Accuracy: 0.4629\n",
      "Epoch 27/100, Test Loss: 1.8375, Test Accuracy: 0.2423\n",
      "Epoch 28/100, Train Loss: 1.2773, Train Accuracy: 0.4695\n",
      "Epoch 28/100, Test Loss: 1.9436, Test Accuracy: 0.1801\n",
      "Epoch 29/100, Train Loss: 1.2759, Train Accuracy: 0.4645\n",
      "Epoch 29/100, Test Loss: 1.8268, Test Accuracy: 0.1717\n",
      "Epoch 30/100, Train Loss: 1.2702, Train Accuracy: 0.4746\n",
      "Epoch 30/100, Test Loss: 2.1723, Test Accuracy: 0.1888\n",
      "Epoch 31/100, Train Loss: 1.2634, Train Accuracy: 0.4767\n",
      "Epoch 31/100, Test Loss: 1.7661, Test Accuracy: 0.1834\n",
      "Epoch 32/100, Train Loss: 1.2635, Train Accuracy: 0.4736\n",
      "Epoch 32/100, Test Loss: 2.1288, Test Accuracy: 0.1794\n",
      "Epoch 33/100, Train Loss: 1.2521, Train Accuracy: 0.4810\n",
      "Epoch 33/100, Test Loss: 2.6272, Test Accuracy: 0.2833\n",
      "Epoch 34/100, Train Loss: 1.2513, Train Accuracy: 0.4805\n",
      "Epoch 34/100, Test Loss: 3.1373, Test Accuracy: 0.2833\n",
      "Epoch 35/100, Train Loss: 1.2393, Train Accuracy: 0.4879\n",
      "Epoch 35/100, Test Loss: 2.4747, Test Accuracy: 0.1776\n",
      "Epoch 36/100, Train Loss: 1.2426, Train Accuracy: 0.4851\n",
      "Epoch 36/100, Test Loss: 2.0775, Test Accuracy: 0.1671\n",
      "Epoch 37/100, Train Loss: 1.2372, Train Accuracy: 0.4868\n",
      "Epoch 37/100, Test Loss: 3.0079, Test Accuracy: 0.2833\n",
      "Epoch 38/100, Train Loss: 1.2374, Train Accuracy: 0.4861\n",
      "Epoch 38/100, Test Loss: 2.5117, Test Accuracy: 0.1761\n",
      "Epoch 39/100, Train Loss: 1.2297, Train Accuracy: 0.4896\n",
      "Epoch 39/100, Test Loss: 1.9639, Test Accuracy: 0.1789\n",
      "Epoch 40/100, Train Loss: 1.2225, Train Accuracy: 0.5019\n",
      "Epoch 40/100, Test Loss: 1.6756, Test Accuracy: 0.2810\n",
      "Epoch 41/100, Train Loss: 1.2235, Train Accuracy: 0.4937\n",
      "Epoch 41/100, Test Loss: 1.8783, Test Accuracy: 0.1666\n",
      "Epoch 42/100, Train Loss: 1.2200, Train Accuracy: 0.4926\n",
      "Epoch 42/100, Test Loss: 1.9292, Test Accuracy: 0.1791\n",
      "Epoch 43/100, Train Loss: 1.2161, Train Accuracy: 0.4959\n",
      "Epoch 43/100, Test Loss: 2.1082, Test Accuracy: 0.1791\n",
      "Epoch 44/100, Train Loss: 1.2115, Train Accuracy: 0.5018\n",
      "Epoch 44/100, Test Loss: 2.1016, Test Accuracy: 0.1791\n",
      "Epoch 45/100, Train Loss: 1.2130, Train Accuracy: 0.5039\n",
      "Epoch 45/100, Test Loss: 2.3544, Test Accuracy: 0.1936\n",
      "Epoch 46/100, Train Loss: 1.2014, Train Accuracy: 0.5096\n",
      "Epoch 46/100, Test Loss: 2.6987, Test Accuracy: 0.1791\n",
      "Epoch 47/100, Train Loss: 1.2031, Train Accuracy: 0.5035\n",
      "Epoch 47/100, Test Loss: 2.0743, Test Accuracy: 0.1761\n",
      "Epoch 48/100, Train Loss: 1.1923, Train Accuracy: 0.5105\n",
      "Epoch 48/100, Test Loss: 1.8973, Test Accuracy: 0.1664\n",
      "Epoch 49/100, Train Loss: 1.1921, Train Accuracy: 0.5126\n",
      "Epoch 49/100, Test Loss: 2.3358, Test Accuracy: 0.1761\n",
      "Epoch 50/100, Train Loss: 1.1898, Train Accuracy: 0.5098\n",
      "Epoch 50/100, Test Loss: 2.7029, Test Accuracy: 0.2833\n",
      "Epoch 51/100, Train Loss: 1.1924, Train Accuracy: 0.5128\n",
      "Epoch 51/100, Test Loss: 2.3722, Test Accuracy: 0.2833\n",
      "Epoch 52/100, Train Loss: 1.1835, Train Accuracy: 0.5178\n",
      "Epoch 52/100, Test Loss: 2.1533, Test Accuracy: 0.2874\n",
      "Epoch 53/100, Train Loss: 1.1862, Train Accuracy: 0.5117\n",
      "Epoch 53/100, Test Loss: 1.8569, Test Accuracy: 0.2833\n",
      "Epoch 54/100, Train Loss: 1.1758, Train Accuracy: 0.5207\n",
      "Epoch 54/100, Test Loss: 1.8768, Test Accuracy: 0.1952\n",
      "Epoch 55/100, Train Loss: 1.1719, Train Accuracy: 0.5210\n",
      "Epoch 55/100, Test Loss: 2.3263, Test Accuracy: 0.1664\n",
      "Epoch 56/100, Train Loss: 1.1732, Train Accuracy: 0.5162\n",
      "Epoch 56/100, Test Loss: 2.2673, Test Accuracy: 0.2833\n",
      "Epoch 57/100, Train Loss: 1.1575, Train Accuracy: 0.5306\n",
      "Epoch 57/100, Test Loss: 3.2847, Test Accuracy: 0.1761\n",
      "Epoch 58/100, Train Loss: 1.1649, Train Accuracy: 0.5267\n",
      "Epoch 58/100, Test Loss: 3.0610, Test Accuracy: 0.1954\n",
      "Epoch 59/100, Train Loss: 1.1650, Train Accuracy: 0.5219\n",
      "Epoch 59/100, Test Loss: 2.2412, Test Accuracy: 0.1761\n",
      "Epoch 60/100, Train Loss: 1.1537, Train Accuracy: 0.5276\n",
      "Epoch 60/100, Test Loss: 2.0550, Test Accuracy: 0.1676\n",
      "Epoch 61/100, Train Loss: 1.1605, Train Accuracy: 0.5247\n",
      "Epoch 61/100, Test Loss: 2.5128, Test Accuracy: 0.1656\n",
      "Epoch 62/100, Train Loss: 1.1519, Train Accuracy: 0.5329\n",
      "Epoch 62/100, Test Loss: 2.0982, Test Accuracy: 0.1946\n",
      "Epoch 63/100, Train Loss: 1.1506, Train Accuracy: 0.5316\n",
      "Epoch 63/100, Test Loss: 2.7664, Test Accuracy: 0.2833\n",
      "Epoch 64/100, Train Loss: 1.1426, Train Accuracy: 0.5379\n",
      "Epoch 64/100, Test Loss: 1.8123, Test Accuracy: 0.2833\n",
      "Epoch 65/100, Train Loss: 1.1462, Train Accuracy: 0.5311\n",
      "Epoch 65/100, Test Loss: 2.1588, Test Accuracy: 0.1638\n",
      "Epoch 66/100, Train Loss: 1.1378, Train Accuracy: 0.5389\n",
      "Epoch 66/100, Test Loss: 2.3992, Test Accuracy: 0.2859\n",
      "Epoch 67/100, Train Loss: 1.1287, Train Accuracy: 0.5402\n",
      "Epoch 67/100, Test Loss: 3.0370, Test Accuracy: 0.1758\n",
      "Epoch 68/100, Train Loss: 1.1316, Train Accuracy: 0.5394\n",
      "Epoch 68/100, Test Loss: 2.5880, Test Accuracy: 0.1761\n",
      "Epoch 69/100, Train Loss: 1.1327, Train Accuracy: 0.5375\n",
      "Epoch 69/100, Test Loss: 2.4033, Test Accuracy: 0.1819\n",
      "Epoch 70/100, Train Loss: 1.1291, Train Accuracy: 0.5450\n",
      "Epoch 70/100, Test Loss: 3.7815, Test Accuracy: 0.1761\n",
      "Epoch 71/100, Train Loss: 1.1279, Train Accuracy: 0.5386\n",
      "Epoch 71/100, Test Loss: 1.9030, Test Accuracy: 0.1750\n",
      "Epoch 72/100, Train Loss: 1.1216, Train Accuracy: 0.5460\n",
      "Epoch 72/100, Test Loss: 1.8080, Test Accuracy: 0.1684\n",
      "Epoch 73/100, Train Loss: 1.1268, Train Accuracy: 0.5466\n",
      "Epoch 73/100, Test Loss: 1.8172, Test Accuracy: 0.1847\n",
      "Epoch 74/100, Train Loss: 1.1143, Train Accuracy: 0.5465\n",
      "Epoch 74/100, Test Loss: 3.0350, Test Accuracy: 0.1761\n",
      "Epoch 75/100, Train Loss: 1.1139, Train Accuracy: 0.5473\n",
      "Epoch 75/100, Test Loss: 1.7813, Test Accuracy: 0.2535\n",
      "Epoch 76/100, Train Loss: 1.1175, Train Accuracy: 0.5507\n",
      "Epoch 76/100, Test Loss: 2.9014, Test Accuracy: 0.1801\n",
      "Epoch 77/100, Train Loss: 1.1077, Train Accuracy: 0.5518\n",
      "Epoch 77/100, Test Loss: 3.6648, Test Accuracy: 0.1791\n",
      "Epoch 78/100, Train Loss: 1.1051, Train Accuracy: 0.5529\n",
      "Epoch 78/100, Test Loss: 2.8237, Test Accuracy: 0.1761\n",
      "Epoch 79/100, Train Loss: 1.0941, Train Accuracy: 0.5583\n",
      "Epoch 79/100, Test Loss: 2.8209, Test Accuracy: 0.2831\n",
      "Epoch 80/100, Train Loss: 1.1019, Train Accuracy: 0.5497\n",
      "Epoch 80/100, Test Loss: 1.7376, Test Accuracy: 0.2581\n",
      "Epoch 81/100, Train Loss: 1.0942, Train Accuracy: 0.5532\n",
      "Epoch 81/100, Test Loss: 3.1530, Test Accuracy: 0.1710\n",
      "Epoch 82/100, Train Loss: 1.0962, Train Accuracy: 0.5569\n",
      "Epoch 82/100, Test Loss: 2.7204, Test Accuracy: 0.2838\n",
      "Epoch 83/100, Train Loss: 1.0968, Train Accuracy: 0.5552\n",
      "Epoch 83/100, Test Loss: 2.7283, Test Accuracy: 0.2833\n",
      "Epoch 84/100, Train Loss: 1.0878, Train Accuracy: 0.5593\n",
      "Epoch 84/100, Test Loss: 2.2434, Test Accuracy: 0.1952\n",
      "Epoch 85/100, Train Loss: 1.0861, Train Accuracy: 0.5567\n",
      "Epoch 85/100, Test Loss: 1.9053, Test Accuracy: 0.2836\n",
      "Epoch 86/100, Train Loss: 1.0900, Train Accuracy: 0.5617\n",
      "Epoch 86/100, Test Loss: 1.8990, Test Accuracy: 0.1776\n",
      "Epoch 87/100, Train Loss: 1.0809, Train Accuracy: 0.5639\n",
      "Epoch 87/100, Test Loss: 2.9270, Test Accuracy: 0.2833\n",
      "Epoch 88/100, Train Loss: 1.0797, Train Accuracy: 0.5653\n",
      "Epoch 88/100, Test Loss: 1.7139, Test Accuracy: 0.2739\n",
      "Epoch 89/100, Train Loss: 1.0777, Train Accuracy: 0.5646\n",
      "Epoch 89/100, Test Loss: 2.5875, Test Accuracy: 0.1791\n",
      "Epoch 90/100, Train Loss: 1.0824, Train Accuracy: 0.5650\n",
      "Epoch 90/100, Test Loss: 3.4978, Test Accuracy: 0.1862\n",
      "Epoch 91/100, Train Loss: 1.0774, Train Accuracy: 0.5627\n",
      "Epoch 91/100, Test Loss: 1.8961, Test Accuracy: 0.2833\n",
      "Epoch 92/100, Train Loss: 1.0773, Train Accuracy: 0.5627\n",
      "Epoch 92/100, Test Loss: 2.1745, Test Accuracy: 0.1992\n",
      "Epoch 93/100, Train Loss: 1.0691, Train Accuracy: 0.5686\n",
      "Epoch 93/100, Test Loss: 2.3590, Test Accuracy: 0.1758\n",
      "Epoch 94/100, Train Loss: 1.0609, Train Accuracy: 0.5709\n",
      "Epoch 94/100, Test Loss: 4.1380, Test Accuracy: 0.1791\n",
      "Epoch 95/100, Train Loss: 1.0678, Train Accuracy: 0.5667\n",
      "Epoch 95/100, Test Loss: 2.7913, Test Accuracy: 0.1791\n",
      "Epoch 96/100, Train Loss: 1.0659, Train Accuracy: 0.5679\n",
      "Epoch 96/100, Test Loss: 3.8014, Test Accuracy: 0.1761\n",
      "Epoch 97/100, Train Loss: 1.0640, Train Accuracy: 0.5651\n",
      "Epoch 97/100, Test Loss: 2.9082, Test Accuracy: 0.1878\n",
      "Epoch 98/100, Train Loss: 1.0612, Train Accuracy: 0.5690\n",
      "Epoch 98/100, Test Loss: 6.1360, Test Accuracy: 0.2833\n",
      "Epoch 99/100, Train Loss: 1.0556, Train Accuracy: 0.5730\n",
      "Epoch 99/100, Test Loss: 3.1076, Test Accuracy: 0.2846\n",
      "Epoch 100/100, Train Loss: 1.0545, Train Accuracy: 0.5721\n",
      "Epoch 100/100, Test Loss: 3.0990, Test Accuracy: 0.1791\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 루프\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, correct_train = 0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.unsqueeze(1)  # (batch_size, 1, features)\n",
    "        inputs = inputs.transpose(1, 2)  # (batch_size, features, 1) -> (batch_size, 1, features)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy = correct_train / len(train_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, correct_test = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.unsqueeze(1)  # (batch_size, 1, features)\n",
    "            inputs = inputs.transpose(1, 2)  # (batch_size, features, 1) -> (batch_size, 1, features)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = correct_test / len(test_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
