{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a title=\"Activity Recognition\" href=\"https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition\" > LSTMs for Human Activity Recognition</a>\n",
    "\n",
    "Human Activity Recognition (HAR) using smartphones dataset and an LSTM RNN. Classifying the type of movement amongst six categories:\n",
    "- WALKING,\n",
    "- WALKING_UPSTAIRS,\n",
    "- WALKING_DOWNSTAIRS,\n",
    "- SITTING,\n",
    "- STANDING,\n",
    "- LAYING.\n",
    "\n",
    "Compared to a classical approach, using a Recurrent Neural Networks (RNN) with Long Short-Term Memory cells (LSTMs) require no or almost no feature engineering. Data can be fed directly into the neural network who acts like a black box, modeling the problem correctly. [Other research](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names) on the activity recognition dataset can use a big amount of feature engineering, which is rather a signal processing approach combined with classical data science techniques. The approach here is rather very simple in terms of how much was the data preprocessed. \n",
    "\n",
    "Let's use Google's neat Deep Learning library, TensorFlow, demonstrating the usage of an LSTM, a type of Artificial Neural Network that can process sequential data / time series. \n",
    "\n",
    "## Video dataset overview\n",
    "\n",
    "Follow this link to see a video of the 6 activities recorded in the experiment with one of the participants:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a href=\"http://www.youtube.com/watch?feature=player_embedded&v=XOEN9W05_4A\n",
    "\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/XOEN9W05_4A/0.jpg\" \n",
    "alt=\"Video of the experiment\" width=\"400\" height=\"300\" border=\"10\" /></a>\n",
    "  <a href=\"https://youtu.be/XOEN9W05_4A\"><center>[Watch video]</center></a>\n",
    "</p>\n",
    "\n",
    "## Details about the input data\n",
    "\n",
    "I will be using an LSTM on the data to learn (as a cellphone attached on the waist) to recognise the type of activity that the user is doing. The dataset's description goes like this:\n",
    "\n",
    "> The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. \n",
    "\n",
    "That said, I will use the almost raw data: only the gravity effect has been filtered out of the accelerometer  as a preprocessing step for another 3D feature as an input to help learning. If you'd ever want to extract the gravity by yourself, you could fork my code on using a [Butterworth Low-Pass Filter (LPF) in Python](https://github.com/guillaume-chevalier/filtering-stft-and-laplace-transform) and edit it to have the right cutoff frequency of 0.3 Hz which is a good frequency for activity recognition from body sensors.\n",
    "\n",
    "## What is an RNN?\n",
    "\n",
    "As explained in [this article](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), an RNN takes many input vectors to process them and output other vectors. It can be roughly pictured like in the image below, imagining each rectangle has a vectorial depth and other special hidden quirks in the image below. **In our case, the \"many to one\" architecture is used**: we accept time series of [feature vectors](https://www.quora.com/What-do-samples-features-time-steps-mean-in-LSTM/answer/Guillaume-Chevalier-2) (one vector per [time step](https://www.quora.com/What-do-samples-features-time-steps-mean-in-LSTM/answer/Guillaume-Chevalier-2)) to convert them to a probability vector at the output for classification. Note that a \"one to one\" architecture would be a standard feedforward neural network. \n",
    "\n",
    "> <a href=\"https://www.dl-rnn-course.neuraxio.com/start?utm_source=github_lstm\" ><img src=\"https://raw.githubusercontent.com/Neuraxio/Machine-Learning-Figures/master/rnn-architectures.png\" /></a>\n",
    "> [Learn more on RNNs](https://www.dl-rnn-course.neuraxio.com/start?utm_source=github_lstm)\n",
    "\n",
    "## What is an LSTM?\n",
    "\n",
    "An LSTM is an improved RNN. It is more complex, but easier to train, avoiding what is called the vanishing gradient problem. I recommend [this course](https://www.dl-rnn-course.neuraxio.com/start?utm_source=github_lstm) for you to learn more on LSTMs.\n",
    "\n",
    "> [Learn more on LSTMs](https://www.dl-rnn-course.neuraxio.com/start?utm_source=github_lstm)\n",
    "\n",
    "\n",
    "## Results \n",
    "\n",
    "Scroll on! Nice visuals awaits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Includes\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Constants\n",
    "\n",
    "# Those are separate normalised input features for the neural network\n",
    "INPUT_SIGNAL_TYPES = [\n",
    "    # \"body_acc_x_\",\n",
    "    # \"body_acc_y_\",\n",
    "    # \"body_acc_z_\",\n",
    "    \"body_gyro_x_\",\n",
    "    \"body_gyro_y_\",\n",
    "    \"body_gyro_z_\",\n",
    "    # \"total_acc_x_\",\n",
    "    # \"total_acc_y_\",\n",
    "    # \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "# Output classes to learn how to classify\n",
    "LABELS = [\n",
    "    \"WALKING\",\n",
    "    \"WALKING_UPSTAIRS\",\n",
    "    \"WALKING_DOWNSTAIRS\",\n",
    "    \"SITTING\",\n",
    "    \"STANDING\",\n",
    "    \"LAYING\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start by downloading the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading...\n",
      "Dataset already downloaded. Did not download twice.\n",
      "\n",
      "Extracting...\n",
      "Dataset already extracted. Did not extract twice.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset is now located at: data/UCI HAR Dataset/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Note: Linux bash commands start with a \"!\" inside those \"ipython notebook\" cells\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "\n",
    "!pwd && ls\n",
    "os.chdir(DATA_PATH)\n",
    "!pwd && ls\n",
    "\n",
    "!python download_dataset.py\n",
    "\n",
    "!pwd && ls\n",
    "os.chdir(\"..\")\n",
    "!pwd && ls\n",
    "\n",
    "DATASET_PATH = DATA_PATH + \"UCI HAR Dataset/\"\n",
    "print(\"\\n\" + \"Dataset is now located at: \" + DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = \"train/\"\n",
    "TEST = \"test/\"\n",
    "\n",
    "\n",
    "# Load \"X\" (the neural network's training and testing inputs)\n",
    "\n",
    "def load_X(X_signals_paths):\n",
    "    X_signals = []\n",
    "\n",
    "    for signal_type_path in X_signals_paths:\n",
    "        file = open(signal_type_path, 'r')\n",
    "        # Read dataset from disk, dealing with text files' syntax\n",
    "        X_signals.append(\n",
    "            [np.array(serie, dtype=np.float32) for serie in [\n",
    "                row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "            ]]\n",
    "        )\n",
    "        file.close()\n",
    "\n",
    "    return np.transpose(np.array(X_signals), (1, 2, 0))\n",
    "\n",
    "X_train_signals_paths = [\n",
    "    DATASET_PATH + TRAIN + \"Inertial Signals/\" + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "X_test_signals_paths = [\n",
    "    DATASET_PATH + TEST + \"Inertial Signals/\" + signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n",
    "]\n",
    "\n",
    "X_train = load_X(X_train_signals_paths)\n",
    "X_test = load_X(X_test_signals_paths)\n",
    "\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    # Read dataset from disk, dealing with text file's syntax\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]],\n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "\n",
    "    # Substract 1 to each output class for friendly 0-based indexing\n",
    "    return y_ - 1\n",
    "\n",
    "y_train_path = DATASET_PATH + TRAIN + \"y_train.txt\"\n",
    "y_test_path = DATASET_PATH + TEST + \"y_test.txt\"\n",
    "\n",
    "y_train = load_y(y_train_path)\n",
    "y_test = load_y(y_test_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additionnal Parameters:\n",
    "\n",
    "Here are some core parameter definitions for the training. \n",
    "\n",
    "For example, the whole neural network's structure could be summarised by enumerating those parameters and the fact that two LSTM are used one on top of another (stacked) output-to-input as hidden layers through time steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "(2947, 128, 3) (2947, 1) -0.0029600263 0.33441213\n",
      "The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "# Input Data\n",
    "\n",
    "training_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\n",
    "test_data_count = len(X_test)  # 2947 testing series\n",
    "n_steps = len(X_train[0])  # 128 timesteps per series\n",
    "n_input = len(X_train[0][0])  # 9 input parameters per timestep\n",
    "\n",
    "\n",
    "# LSTM Neural Network's internal structure\n",
    "\n",
    "n_hidden = 128 # Hidden layer num of features\n",
    "n_classes = 6 # Total classes (should go up, or should go down)\n",
    "\n",
    "\n",
    "# Training\n",
    "\n",
    "learning_rate = 0.0001\n",
    "lambda_loss_amount = 0.0015\n",
    "training_iters = training_data_count * 300  # Loop 300 times on the dataset\n",
    "batch_size = 1000\n",
    "display_iter = 30000  # To show test set accuracy during training\n",
    "\n",
    "\n",
    "# Some debugging info\n",
    "\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_RNN(input_shape, n_classes, n_hidden):\n",
    "    \"\"\"\n",
    "    TensorFlow 2.x 스타일의 LSTM RNN 모델 정의\n",
    "    input_shape: (타임 스텝, 입력 특성 수)\n",
    "    n_classes: 출력 클래스 수\n",
    "    n_hidden: LSTM 셀의 뉴런 수\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # 첫 번째 LSTM 레이어\n",
    "    model.add(tf.keras.layers.LSTM(n_hidden, return_sequences=True,\n",
    "                                   input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "    # 두 번째 LSTM 레이어\n",
    "    model.add(tf.keras.layers.LSTM(n_hidden))\n",
    "\n",
    "    # Dense 레이어 (출력층 전)\n",
    "    model.add(tf.keras.layers.Dense(n_hidden, activation='relu', \n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(0.001))) # L2 정규화 추가\n",
    "    model.add(tf.keras.layers.BatchNormalization())  # 배치 정규화 추가\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "    # 출력층\n",
    "    model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# y_train과 y_test에 원-핫 인코딩 적용\n",
    "y_train = to_categorical(y_train, num_classes=n_classes)\n",
    "y_test = to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "# 배치 데이터를 추출하는 함수\n",
    "def extract_batch_size(data, step, batch_size):\n",
    "    \"\"\"배치 데이터를 추출하는 함수\"\"\"\n",
    "    start_index = (step - 1) * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "\n",
    "    # 데이터가 끝까지 도달했을 경우 남은 데이터만 추출\n",
    "    if end_index > len(data):\n",
    "        end_index = len(data)\n",
    "\n",
    "    batch_s = data[start_index:end_index]\n",
    "    \n",
    "    return batch_s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get serious and build the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "115/115 [==============================] - 19s 133ms/step - loss: 1.3670 - accuracy: 0.4217 - val_loss: 1.5545 - val_accuracy: 0.5025\n",
      "Epoch 2/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 1.0598 - accuracy: 0.5437 - val_loss: 1.1787 - val_accuracy: 0.5490\n",
      "Epoch 3/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.9031 - accuracy: 0.5890 - val_loss: 1.0623 - val_accuracy: 0.5382\n",
      "Epoch 4/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.8503 - accuracy: 0.6047 - val_loss: 1.0653 - val_accuracy: 0.5484\n",
      "Epoch 5/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.8061 - accuracy: 0.6136 - val_loss: 0.9084 - val_accuracy: 0.5928\n",
      "Epoch 6/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.6317 - accuracy: 0.6831 - val_loss: 0.8394 - val_accuracy: 0.6963\n",
      "Epoch 16/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.6514 - accuracy: 0.6680 - val_loss: 0.8600 - val_accuracy: 0.6566\n",
      "Epoch 17/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.6433 - accuracy: 0.6861 - val_loss: 0.7775 - val_accuracy: 0.6949\n",
      "Epoch 18/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.6261 - accuracy: 0.6889 - val_loss: 0.8134 - val_accuracy: 0.6736\n",
      "Epoch 19/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.6341 - accuracy: 0.6936 - val_loss: 0.6938 - val_accuracy: 0.6932\n",
      "Epoch 20/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.5963 - accuracy: 0.7042 - val_loss: 0.7871 - val_accuracy: 0.6318\n",
      "Epoch 21/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.5664 - accuracy: 0.7263 - val_loss: 0.7286 - val_accuracy: 0.7095\n",
      "Epoch 22/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.5491 - accuracy: 0.7314 - val_loss: 0.6921 - val_accuracy: 0.7343\n",
      "Epoch 23/200\n",
      "115/115 [==============================] - 15s 132ms/step - loss: 0.5541 - accuracy: 0.7320 - val_loss: 0.7127 - val_accuracy: 0.6841\n",
      "Epoch 24/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.5337 - accuracy: 0.7409 - val_loss: 0.8213 - val_accuracy: 0.6916\n",
      "Epoch 25/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.5349 - accuracy: 0.7492 - val_loss: 0.7124 - val_accuracy: 0.7085\n",
      "Epoch 26/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.5418 - accuracy: 0.7447 - val_loss: 0.6666 - val_accuracy: 0.7292\n",
      "Epoch 27/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.5281 - accuracy: 0.7497 - val_loss: 0.6760 - val_accuracy: 0.7367\n",
      "Epoch 28/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.5640 - accuracy: 0.7254 - val_loss: 0.7165 - val_accuracy: 0.7085\n",
      "Epoch 29/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.5106 - accuracy: 0.7622 - val_loss: 0.7031 - val_accuracy: 0.7465\n",
      "Epoch 30/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.5177 - accuracy: 0.7586 - val_loss: 0.7261 - val_accuracy: 0.7302\n",
      "Epoch 31/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.4811 - accuracy: 0.7817 - val_loss: 0.6814 - val_accuracy: 0.7509\n",
      "Epoch 32/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.4700 - accuracy: 0.7848 - val_loss: 0.7364 - val_accuracy: 0.7258\n",
      "Epoch 33/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.4511 - accuracy: 0.8145 - val_loss: 0.7951 - val_accuracy: 0.7177\n",
      "Epoch 45/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.4558 - accuracy: 0.8074 - val_loss: 0.6920 - val_accuracy: 0.7370\n",
      "Epoch 46/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.4406 - accuracy: 0.8143 - val_loss: 0.6489 - val_accuracy: 0.7801\n",
      "Epoch 47/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.4027 - accuracy: 0.8339 - val_loss: 0.5852 - val_accuracy: 0.8015\n",
      "Epoch 48/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.5153 - accuracy: 0.7584 - val_loss: 0.6481 - val_accuracy: 0.7686\n",
      "Epoch 49/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.4062 - accuracy: 0.8347 - val_loss: 0.6078 - val_accuracy: 0.7883\n",
      "Epoch 50/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.4113 - accuracy: 0.8285 - val_loss: 0.6138 - val_accuracy: 0.7903\n",
      "Epoch 51/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.3853 - accuracy: 0.8399 - val_loss: 0.5929 - val_accuracy: 0.7971\n",
      "Epoch 52/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.3839 - accuracy: 0.8451 - val_loss: 0.6020 - val_accuracy: 0.7950\n",
      "Epoch 53/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.3513 - accuracy: 0.8618 - val_loss: 0.7182 - val_accuracy: 0.7862\n",
      "Epoch 54/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.3411 - accuracy: 0.8653 - val_loss: 0.6014 - val_accuracy: 0.7876\n",
      "Epoch 55/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.3334 - accuracy: 0.8679 - val_loss: 0.6036 - val_accuracy: 0.7974\n",
      "Epoch 56/200\n",
      "115/115 [==============================] - 15s 132ms/step - loss: 0.3338 - accuracy: 0.8660 - val_loss: 0.5906 - val_accuracy: 0.8056\n",
      "Epoch 57/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.3245 - accuracy: 0.8720 - val_loss: 0.5911 - val_accuracy: 0.8035\n",
      "Epoch 58/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.2815 - accuracy: 0.8931 - val_loss: 0.6504 - val_accuracy: 0.8147\n",
      "Epoch 64/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.3153 - accuracy: 0.8802 - val_loss: 0.8117 - val_accuracy: 0.8029\n",
      "Epoch 65/200\n",
      "115/115 [==============================] - 15s 134ms/step - loss: 0.2914 - accuracy: 0.8890 - val_loss: 0.6154 - val_accuracy: 0.8015\n",
      "Epoch 66/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.2900 - accuracy: 0.8927 - val_loss: 0.6366 - val_accuracy: 0.8124\n",
      "Epoch 67/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.3161 - accuracy: 0.8788 - val_loss: 0.6817 - val_accuracy: 0.7825\n",
      "Epoch 68/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.2687 - accuracy: 0.8979 - val_loss: 0.6408 - val_accuracy: 0.8137\n",
      "Epoch 69/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.2306 - accuracy: 0.9124 - val_loss: 0.5731 - val_accuracy: 0.8171\n",
      "Epoch 75/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.2391 - accuracy: 0.9125 - val_loss: 0.6545 - val_accuracy: 0.8090\n",
      "Epoch 76/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.2252 - accuracy: 0.9178 - val_loss: 0.6469 - val_accuracy: 0.8073\n",
      "Epoch 77/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.2373 - accuracy: 0.9113 - val_loss: 0.7415 - val_accuracy: 0.8103\n",
      "Epoch 78/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.2449 - accuracy: 0.9075 - val_loss: 0.6796 - val_accuracy: 0.8062\n",
      "Epoch 79/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.2132 - accuracy: 0.9240 - val_loss: 0.6769 - val_accuracy: 0.8049\n",
      "Epoch 80/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.2138 - accuracy: 0.9251 - val_loss: 0.6408 - val_accuracy: 0.8327\n",
      "Epoch 81/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.2050 - accuracy: 0.9268 - val_loss: 0.6338 - val_accuracy: 0.8124\n",
      "Epoch 82/200\n",
      "115/115 [==============================] - 14s 122ms/step - loss: 0.1862 - accuracy: 0.9327 - val_loss: 0.6497 - val_accuracy: 0.8029\n",
      "Epoch 83/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.2050 - accuracy: 0.9274 - val_loss: 0.6401 - val_accuracy: 0.8191\n",
      "Epoch 84/200\n",
      "115/115 [==============================] - 15s 126ms/step - loss: 0.1858 - accuracy: 0.9365 - val_loss: 0.6431 - val_accuracy: 0.8208\n",
      "Epoch 85/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.1920 - accuracy: 0.9286 - val_loss: 0.6611 - val_accuracy: 0.8239\n",
      "Epoch 86/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.1965 - accuracy: 0.9291 - val_loss: 0.6851 - val_accuracy: 0.8032\n",
      "Epoch 87/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.1986 - accuracy: 0.9338 - val_loss: 0.7239 - val_accuracy: 0.8093\n",
      "Epoch 88/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.1860 - accuracy: 0.9325 - val_loss: 0.6969 - val_accuracy: 0.8130\n",
      "Epoch 89/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.1887 - accuracy: 0.9347 - val_loss: 0.6978 - val_accuracy: 0.8076\n",
      "Epoch 90/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.1758 - accuracy: 0.9399 - val_loss: 0.6800 - val_accuracy: 0.8178\n",
      "Epoch 91/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.1759 - accuracy: 0.9376 - val_loss: 0.7092 - val_accuracy: 0.8110\n",
      "Epoch 92/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.1483 - accuracy: 0.9474 - val_loss: 0.7328 - val_accuracy: 0.8171\n",
      "Epoch 93/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.1560 - accuracy: 0.9486 - val_loss: 0.7141 - val_accuracy: 0.8144\n",
      "Epoch 94/200\n",
      "115/115 [==============================] - 15s 128ms/step - loss: 0.1407 - accuracy: 0.9527 - val_loss: 0.7554 - val_accuracy: 0.8242\n",
      "Epoch 102/200\n",
      "115/115 [==============================] - 16s 138ms/step - loss: 0.1360 - accuracy: 0.9551 - val_loss: 0.7713 - val_accuracy: 0.8202\n",
      "Epoch 103/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.1590 - accuracy: 0.9453 - val_loss: 0.8828 - val_accuracy: 0.8202\n",
      "Epoch 104/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.1361 - accuracy: 0.9576 - val_loss: 0.8008 - val_accuracy: 0.8320\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.1122 - accuracy: 0.9625 - val_loss: 0.8467 - val_accuracy: 0.8249\n",
      "Epoch 112/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.1097 - accuracy: 0.9634 - val_loss: 0.7843 - val_accuracy: 0.8283\n",
      "Epoch 113/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.1138 - accuracy: 0.9621 - val_loss: 0.8381 - val_accuracy: 0.8246\n",
      "Epoch 114/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.1189 - accuracy: 0.9606 - val_loss: 0.9228 - val_accuracy: 0.8219\n",
      "Epoch 115/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.1144 - accuracy: 0.9629 - val_loss: 0.8390 - val_accuracy: 0.8273\n",
      "Epoch 116/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.1163 - accuracy: 0.9630 - val_loss: 0.8278 - val_accuracy: 0.8276\n",
      "Epoch 117/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.1050 - accuracy: 0.9661 - val_loss: 0.8516 - val_accuracy: 0.8235\n",
      "Epoch 118/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0890 - accuracy: 0.9689 - val_loss: 0.8501 - val_accuracy: 0.8280\n",
      "Epoch 119/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0926 - accuracy: 0.9705 - val_loss: 0.8705 - val_accuracy: 0.8246\n",
      "Epoch 120/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0880 - accuracy: 0.9712 - val_loss: 0.9082 - val_accuracy: 0.8164\n",
      "Epoch 121/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.1029 - accuracy: 0.9675 - val_loss: 0.8790 - val_accuracy: 0.8341\n",
      "Epoch 122/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.0812 - accuracy: 0.9751 - val_loss: 0.8747 - val_accuracy: 0.8246\n",
      "Epoch 123/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.0872 - accuracy: 0.9720 - val_loss: 0.9629 - val_accuracy: 0.8056\n",
      "Epoch 124/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0908 - accuracy: 0.9709 - val_loss: 0.9578 - val_accuracy: 0.8276\n",
      "Epoch 125/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.0904 - accuracy: 0.9716 - val_loss: 0.9556 - val_accuracy: 0.8225\n",
      "Epoch 126/200\n",
      "115/115 [==============================] - 15s 131ms/step - loss: 0.0758 - accuracy: 0.9788 - val_loss: 1.0424 - val_accuracy: 0.8188\n",
      "Epoch 127/200\n",
      "115/115 [==============================] - 15s 131ms/step - loss: 0.1723 - accuracy: 0.9513 - val_loss: 0.8696 - val_accuracy: 0.8120\n",
      "Epoch 128/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.1194 - accuracy: 0.9633 - val_loss: 0.8616 - val_accuracy: 0.8212\n",
      "Epoch 129/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.1058 - accuracy: 0.9694 - val_loss: 0.8167 - val_accuracy: 0.8242\n",
      "Epoch 130/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0877 - accuracy: 0.9758 - val_loss: 0.8352 - val_accuracy: 0.8225\n",
      "Epoch 131/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0720 - accuracy: 0.9758 - val_loss: 0.9688 - val_accuracy: 0.8191\n",
      "Epoch 138/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0770 - accuracy: 0.9754 - val_loss: 0.9183 - val_accuracy: 0.8174\n",
      "Epoch 139/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.0526 - accuracy: 0.9846 - val_loss: 0.9885 - val_accuracy: 0.8280\n",
      "Epoch 140/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 1.0020 - val_accuracy: 0.8297\n",
      "Epoch 141/200\n",
      "115/115 [==============================] - 14s 122ms/step - loss: 0.0983 - accuracy: 0.9678 - val_loss: 0.9832 - val_accuracy: 0.8035\n",
      "Epoch 142/200\n",
      "115/115 [==============================] - 14s 122ms/step - loss: 0.0821 - accuracy: 0.9743 - val_loss: 0.9817 - val_accuracy: 0.8225\n",
      "Epoch 143/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.1123 - accuracy: 0.9641 - val_loss: 0.8198 - val_accuracy: 0.8222\n",
      "Epoch 144/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.1076 - accuracy: 0.9667 - val_loss: 0.8726 - val_accuracy: 0.8144\n",
      "Epoch 145/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.0983 - accuracy: 0.9690 - val_loss: 0.8969 - val_accuracy: 0.8310\n",
      "Epoch 146/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0911 - accuracy: 0.9731 - val_loss: 0.9385 - val_accuracy: 0.8035\n",
      "Epoch 147/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0647 - accuracy: 0.9803 - val_loss: 0.8578 - val_accuracy: 0.8320\n",
      "Epoch 148/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.0473 - accuracy: 0.9872 - val_loss: 0.9425 - val_accuracy: 0.8232\n",
      "Epoch 149/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.0532 - accuracy: 0.9838 - val_loss: 0.8893 - val_accuracy: 0.8263\n",
      "Epoch 150/200\n",
      "115/115 [==============================] - 14s 123ms/step - loss: 0.1120 - accuracy: 0.9652 - val_loss: 0.8710 - val_accuracy: 0.8168\n",
      "Epoch 151/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.0582 - accuracy: 0.9848 - val_loss: 0.9253 - val_accuracy: 0.8198\n",
      "Epoch 152/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0412 - accuracy: 0.9898 - val_loss: 0.9018 - val_accuracy: 0.8120\n",
      "Epoch 153/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.0638 - accuracy: 0.9804 - val_loss: 0.9704 - val_accuracy: 0.8235\n",
      "Epoch 154/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.8921 - val_accuracy: 0.8178\n",
      "Epoch 155/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.0400 - accuracy: 0.9893 - val_loss: 0.9764 - val_accuracy: 0.8293\n",
      "Epoch 156/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.0702 - accuracy: 0.9773 - val_loss: 0.8801 - val_accuracy: 0.8263\n",
      "Epoch 157/200\n",
      "115/115 [==============================] - 15s 126ms/step - loss: 0.0506 - accuracy: 0.9848 - val_loss: 0.9927 - val_accuracy: 0.8161\n",
      "Epoch 158/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0466 - accuracy: 0.9864 - val_loss: 1.0047 - val_accuracy: 0.8263\n",
      "Epoch 159/200\n",
      "115/115 [==============================] - 16s 136ms/step - loss: 0.0541 - accuracy: 0.9837 - val_loss: 0.9330 - val_accuracy: 0.8113\n",
      "Epoch 160/200\n",
      "115/115 [==============================] - 15s 126ms/step - loss: 0.0698 - accuracy: 0.9784 - val_loss: 0.9313 - val_accuracy: 0.8198\n",
      "Epoch 161/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0652 - accuracy: 0.9811 - val_loss: 0.9431 - val_accuracy: 0.8202\n",
      "Epoch 162/200\n",
      "115/115 [==============================] - 15s 132ms/step - loss: 0.0638 - accuracy: 0.9833 - val_loss: 0.9479 - val_accuracy: 0.8246\n",
      "Epoch 163/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.0399 - accuracy: 0.9897 - val_loss: 0.9790 - val_accuracy: 0.8242\n",
      "Epoch 164/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0845 - accuracy: 0.9763 - val_loss: 0.9293 - val_accuracy: 0.8280\n",
      "Epoch 165/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0732 - accuracy: 0.9785 - val_loss: 0.8723 - val_accuracy: 0.8422\n",
      "Epoch 166/200\n",
      "115/115 [==============================] - 15s 126ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.9757 - val_accuracy: 0.8334\n",
      "Epoch 167/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.0614 - accuracy: 0.9805 - val_loss: 1.1101 - val_accuracy: 0.8181\n",
      "Epoch 168/200\n",
      "115/115 [==============================] - 15s 126ms/step - loss: 0.0773 - accuracy: 0.9761 - val_loss: 0.8880 - val_accuracy: 0.8351\n",
      "Epoch 169/200\n",
      "115/115 [==============================] - 15s 126ms/step - loss: 0.0756 - accuracy: 0.9777 - val_loss: 0.8413 - val_accuracy: 0.8351\n",
      "Epoch 170/200\n",
      "115/115 [==============================] - 15s 126ms/step - loss: 0.0671 - accuracy: 0.9830 - val_loss: 0.9010 - val_accuracy: 0.8219\n",
      "Epoch 171/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0573 - accuracy: 0.9863 - val_loss: 1.0136 - val_accuracy: 0.8188\n",
      "Epoch 172/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0438 - accuracy: 0.9899 - val_loss: 1.0572 - val_accuracy: 0.8229\n",
      "Epoch 173/200\n",
      "115/115 [==============================] - 14s 125ms/step - loss: 0.0496 - accuracy: 0.9860 - val_loss: 1.0723 - val_accuracy: 0.8134\n",
      "Epoch 174/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.0639 - accuracy: 0.9829 - val_loss: 0.9628 - val_accuracy: 0.8293\n",
      "Epoch 175/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.0883 - accuracy: 0.9732 - val_loss: 1.0264 - val_accuracy: 0.8120\n",
      "Epoch 176/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.0522 - accuracy: 0.9864 - val_loss: 0.9772 - val_accuracy: 0.8198\n",
      "Epoch 177/200\n",
      "115/115 [==============================] - 15s 129ms/step - loss: 0.0471 - accuracy: 0.9880 - val_loss: 1.0127 - val_accuracy: 0.8263\n",
      "Epoch 178/200\n",
      "115/115 [==============================] - 15s 130ms/step - loss: 0.0451 - accuracy: 0.9894 - val_loss: 1.0772 - val_accuracy: 0.8232\n",
      "Epoch 179/200\n",
      "115/115 [==============================] - 15s 133ms/step - loss: 0.0363 - accuracy: 0.9928 - val_loss: 1.0762 - val_accuracy: 0.8212\n",
      "Epoch 180/200\n",
      "115/115 [==============================] - 15s 129ms/step - loss: 0.0782 - accuracy: 0.9758 - val_loss: 1.1553 - val_accuracy: 0.8039\n",
      "Epoch 181/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.0685 - accuracy: 0.9788 - val_loss: 1.0571 - val_accuracy: 0.8140\n",
      "Epoch 182/200\n",
      "115/115 [==============================] - 15s 128ms/step - loss: 0.0609 - accuracy: 0.9846 - val_loss: 0.9709 - val_accuracy: 0.8334\n",
      "Epoch 183/200\n",
      "115/115 [==============================] - 15s 126ms/step - loss: 0.0481 - accuracy: 0.9876 - val_loss: 1.0593 - val_accuracy: 0.8317\n",
      "Epoch 184/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.0334 - accuracy: 0.9924 - val_loss: 0.9987 - val_accuracy: 0.8307\n",
      "Epoch 185/200\n",
      "115/115 [==============================] - 15s 128ms/step - loss: 0.0397 - accuracy: 0.9902 - val_loss: 0.9874 - val_accuracy: 0.8249\n",
      "Epoch 186/200\n",
      "115/115 [==============================] - 14s 124ms/step - loss: 0.0589 - accuracy: 0.9845 - val_loss: 0.9914 - val_accuracy: 0.8280\n",
      "Epoch 187/200\n",
      "115/115 [==============================] - 15s 128ms/step - loss: 0.0286 - accuracy: 0.9940 - val_loss: 1.0195 - val_accuracy: 0.8297\n",
      "Epoch 188/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0232 - accuracy: 0.9950 - val_loss: 1.0192 - val_accuracy: 0.8249\n",
      "Epoch 189/200\n",
      "115/115 [==============================] - 15s 129ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 1.1101 - val_accuracy: 0.8307\n",
      "Epoch 190/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0604 - accuracy: 0.9835 - val_loss: 1.0876 - val_accuracy: 0.8219\n",
      "Epoch 191/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0374 - accuracy: 0.9909 - val_loss: 1.0752 - val_accuracy: 0.8293\n",
      "Epoch 192/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.0390 - accuracy: 0.9903 - val_loss: 1.0971 - val_accuracy: 0.8096\n",
      "Epoch 193/200\n",
      "115/115 [==============================] - 15s 130ms/step - loss: 0.0497 - accuracy: 0.9888 - val_loss: 1.0520 - val_accuracy: 0.8286\n",
      "Epoch 194/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0453 - accuracy: 0.9882 - val_loss: 1.0055 - val_accuracy: 0.8178\n",
      "Epoch 195/200\n",
      "115/115 [==============================] - 15s 126ms/step - loss: 0.0319 - accuracy: 0.9924 - val_loss: 0.9730 - val_accuracy: 0.8337\n",
      "Epoch 196/200\n",
      "115/115 [==============================] - 15s 127ms/step - loss: 0.0362 - accuracy: 0.9909 - val_loss: 0.9609 - val_accuracy: 0.8344\n",
      "Epoch 197/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0315 - accuracy: 0.9925 - val_loss: 1.0377 - val_accuracy: 0.8388\n",
      "Epoch 198/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 1.1847 - val_accuracy: 0.8181\n",
      "Epoch 199/200\n",
      "115/115 [==============================] - 15s 128ms/step - loss: 0.0606 - accuracy: 0.9812 - val_loss: 1.0000 - val_accuracy: 0.8361\n",
      "Epoch 200/200\n",
      "115/115 [==============================] - 14s 126ms/step - loss: 0.0436 - accuracy: 0.9887 - val_loss: 0.9999 - val_accuracy: 0.8307\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.9999 - accuracy: 0.8307\n",
      "Test Accuracy: 0.8306752443313599\n"
     ]
    }
   ],
   "source": [
    "# Graph weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random.normal([n_input, n_hidden])),  # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random.normal([n_hidden, n_classes], mean=1.0))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random.normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random.normal([n_classes]))\n",
    "}\n",
    "\n",
    "input_shape=(X_train.shape[1], 3)  # 입력 데이터의 형태\n",
    "\n",
    "# LSTM 모델 생성\n",
    "model = LSTM_RNN(input_shape, n_classes, n_hidden)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# # 모델 학습이 끝난 후 모델을 저장\n",
    "# model.save('LSTM_model(Gyro_3axis).h5')  # 모델을 h5 파일로 저장\n",
    "# print(\"모델이 저장되었습니다: LSTM_model(Gyro_3axis).h5\")\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooray, now train the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iter #64: Batch Loss = 0.116421, Accuracy = 0.968750\n",
      "Training iter #128: Batch Loss = 0.205517, Accuracy = 0.953125\n",
      "Training iter #192: Batch Loss = 0.070190, Accuracy = 0.968750\n",
      "Training iter #256: Batch Loss = 0.035762, Accuracy = 0.984375\n",
      "Training iter #320: Batch Loss = 0.336879, Accuracy = 0.921875\n",
      "Training iter #384: Batch Loss = 0.121441, Accuracy = 0.953125\n",
      "Training iter #448: Batch Loss = 0.121265, Accuracy = 0.937500\n",
      "Training iter #512: Batch Loss = 0.404590, Accuracy = 0.859375\n",
      "Training iter #576: Batch Loss = 0.382770, Accuracy = 0.875000\n",
      "Training iter #640: Batch Loss = 0.264013, Accuracy = 0.921875\n",
      "Training iter #704: Batch Loss = 0.033792, Accuracy = 0.984375\n",
      "Training iter #768: Batch Loss = 0.147992, Accuracy = 0.968750\n",
      "Training iter #832: Batch Loss = 0.266703, Accuracy = 0.921875\n",
      "Training iter #896: Batch Loss = 0.192583, Accuracy = 0.937500\n",
      "Training iter #960: Batch Loss = 0.535101, Accuracy = 0.890625\n",
      "Training iter #1024: Batch Loss = 0.255198, Accuracy = 0.953125\n",
      "Training iter #1088: Batch Loss = 0.433231, Accuracy = 0.843750\n",
      "Training iter #1152: Batch Loss = 0.056880, Accuracy = 0.984375\n",
      "Training iter #1216: Batch Loss = 0.549508, Accuracy = 0.828125\n",
      "Training iter #1280: Batch Loss = 0.053763, Accuracy = 0.984375\n",
      "Training iter #1344: Batch Loss = 0.340598, Accuracy = 0.937500\n",
      "Training iter #1408: Batch Loss = 0.354429, Accuracy = 0.906250\n",
      "Training iter #1472: Batch Loss = 0.068581, Accuracy = 0.984375\n",
      "Training iter #1536: Batch Loss = 0.176180, Accuracy = 0.953125\n",
      "Training iter #1600: Batch Loss = 0.044410, Accuracy = 0.984375\n",
      "Training iter #1664: Batch Loss = 0.267587, Accuracy = 0.921875\n",
      "Training iter #1728: Batch Loss = 0.188243, Accuracy = 0.953125\n",
      "Training iter #1792: Batch Loss = 0.216102, Accuracy = 0.937500\n",
      "Training iter #1856: Batch Loss = 0.191774, Accuracy = 0.953125\n",
      "Training iter #1920: Batch Loss = 0.024446, Accuracy = 1.000000\n",
      "Training iter #1984: Batch Loss = 1.062653, Accuracy = 0.765625\n",
      "Training iter #2048: Batch Loss = 0.332021, Accuracy = 0.906250\n",
      "Training iter #2112: Batch Loss = 0.294535, Accuracy = 0.937500\n",
      "Training iter #2176: Batch Loss = 0.080959, Accuracy = 0.984375\n",
      "Training iter #2240: Batch Loss = 0.182251, Accuracy = 0.937500\n",
      "Training iter #2304: Batch Loss = 0.822557, Accuracy = 0.828125\n",
      "Training iter #2368: Batch Loss = 0.361413, Accuracy = 0.921875\n",
      "Training iter #2432: Batch Loss = 0.170171, Accuracy = 0.968750\n",
      "Training iter #2496: Batch Loss = 0.206816, Accuracy = 0.953125\n",
      "Training iter #2560: Batch Loss = 0.119112, Accuracy = 0.968750\n",
      "Training iter #2624: Batch Loss = 1.119757, Accuracy = 0.890625\n",
      "Training iter #2688: Batch Loss = 0.057202, Accuracy = 0.984375\n",
      "Training iter #2752: Batch Loss = 0.277571, Accuracy = 0.906250\n",
      "Training iter #2816: Batch Loss = 0.273969, Accuracy = 0.890625\n",
      "Training iter #2880: Batch Loss = 0.118085, Accuracy = 0.968750\n",
      "Training iter #2944: Batch Loss = 0.620242, Accuracy = 0.828125\n",
      "Optimization Finished!\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 1.4548 - accuracy: 0.7927\n",
      "FINAL RESULT: Test Loss = 1.454812, Accuracy = 0.792670\n",
      "93/93 [==============================] - 3s 27ms/step\n",
      "Test Accuracy: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# To keep track of training's performance\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# Perform Training steps with \"batch_size\" amount of example data at each loop\n",
    "# 훈련 과정\n",
    "step = 1\n",
    "training_iters = 3000  # 예시로 임의 설정\n",
    "batch_size = 64\n",
    "display_iter = 300  # 몇 번의 반복마다 출력할지 설정\n",
    "\n",
    "while step * batch_size <= training_iters:\n",
    "    batch_xs = extract_batch_size(X_train, step, batch_size)\n",
    "    batch_ys = extract_batch_size(y_train, step, batch_size)  # 이미 원-핫 인코딩된 y_train 사용\n",
    "\n",
    "    # 배치 데이터를 사용해 훈련\n",
    "    history = model.fit(\n",
    "        batch_xs,\n",
    "        batch_ys,\n",
    "        epochs=1,  # 이미 배치별로 처리되고 있으므로 1 에포크만 실행\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # 훈련 손실 및 정확도 출력\n",
    "    loss = history.history['loss'][0]\n",
    "    acc = history.history['accuracy'][0]\n",
    "    print(f\"Training iter #{step * batch_size}: Batch Loss = {loss:.6f}, Accuracy = {acc:.6f}\")\n",
    "\n",
    "    # 테스트 손실 및 정확도 계산\n",
    "    if step * batch_size % display_iter == 0:\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"PERFORMANCE ON TEST SET: Batch Loss = {test_loss:.6f}, Accuracy = {test_acc:.6f}\")\n",
    "\n",
    "    step += 1\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Accuracy for test data\n",
    "\n",
    "# 모델 평가를 위한 수정된 코드\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"FINAL RESULT: Test Loss = {test_loss:.6f}, Accuracy = {test_acc:.6f}\")\n",
    "\n",
    "# 예측값 구하기\n",
    "one_hot_predictions = model.predict(X_test)\n",
    "\n",
    "# 예측값의 최대값 인덱스 가져오기\n",
    "predictions = one_hot_predictions.argmax(axis=1)\n",
    "\n",
    "# 최종 성능 출력\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training is good, but having visual insight is even better:\n",
    "\n",
    "Okay, let's plot this simply in the notebook for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (Inline plots: )\n",
    "%matplotlib inline\n",
    "\n",
    "# matplotlib 폰트 설정을 기본 값으로 설정\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "\n",
    "# 플롯 사이즈 설정\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "indep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size))\n",
    "plt.plot(indep_train_axis, np.array(train_losses), \"b--\", label=\"Train losses\")\n",
    "plt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\")\n",
    "\n",
    "# Test data plotting\n",
    "indep_test_axis = np.array(range(batch_size, len(test_losses)*display_iter, display_iter))\n",
    "plt.plot(indep_test_axis, np.array(test_losses), \"b-\", label=\"Test losses\")\n",
    "plt.plot(indep_test_axis, np.array(test_accuracies), \"g-\", label=\"Test accuracies\")\n",
    "\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.ylabel('Training Progress (Loss or Accuracy values)')\n",
    "plt.xlabel('Training iteration')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And finally, the multi-class confusion matrix and metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Results\u001b[39;00m\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m one_hot_predictions\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting Accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43maccuracy\u001b[49m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mprecision_score(y_test, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "\n",
    "predictions = one_hot_predictions.argmax(1)\n",
    "\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "print(normalised_confusion_matrix)\n",
    "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n",
    "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\")\n",
    "\n",
    "# Plot Results: \n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix, \n",
    "    interpolation='nearest', \n",
    "    cmap=plt.cm.rainbow\n",
    ")\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Outstandingly, **the final accuracy is of 91%**! And it can peak to values such as 93.25%, at some moments of luck during the training, depending on how the neural network's weights got initialized at the start of the training, randomly. \n",
    "\n",
    "This means that the neural networks is almost always able to correctly identify the movement type! Remember, the phone is attached on the waist and each series to classify has just a 128 sample window of two internal sensors (a.k.a. 2.56 seconds at 50 FPS), so it amazes me how those predictions are extremely accurate given this small window of context and raw data. I've validated and re-validated that there is no important bug, and the community used and tried this code a lot. (Note: be sure to report something in the issue tab if you find bugs, otherwise [Quora](https://www.quora.com/), [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow?sort=votes&pageSize=50), and other [StackExchange](https://stackexchange.com/sites#science) sites are the places for asking questions.)\n",
    "\n",
    "I specially did not expect such good results for guessing between the labels \"SITTING\" and \"STANDING\". Those are seemingly almost the same thing from the point of view of a device placed at waist level according to how the dataset was originally gathered. Thought, it is still possible to see a little cluster on the matrix between those classes, which drifts away just a bit from the identity. This is great.\n",
    "\n",
    "It is also possible to see that there was a slight difficulty in doing the difference between \"WALKING\", \"WALKING_UPSTAIRS\" and \"WALKING_DOWNSTAIRS\". Obviously, those activities are quite similar in terms of movements. \n",
    "\n",
    "I also tried my code without the gyroscope, using only the 3D accelerometer's 6 features (and not changing the training hyperparameters), and got an accuracy of 87%. In general, gyroscopes consumes more power than accelerometers, so it is preferable to turn them off. \n",
    "\n",
    "\n",
    "## Improvements\n",
    "\n",
    "In [another open-source repository of mine](https://github.com/guillaume-chevalier/HAR-stacked-residual-bidir-LSTMs), the accuracy is pushed up to nearly 94% using a special deep LSTM architecture which combines the concepts of bidirectional RNNs, residual connections, and stacked cells. This architecture is also tested on another similar activity dataset. It resembles the nice architecture used in \"[Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](https://arxiv.org/pdf/1609.08144.pdf)\", without an attention mechanism, and with just the encoder part - as a \"many to one\" architecture instead of a \"many to many\" to be adapted to the Human Activity Recognition (HAR) problem. I also worked more on the problem and came up with the [LARNN](https://github.com/guillaume-chevalier/Linear-Attention-Recurrent-Neural-Network), however it's complicated for just a little gain. Thus the current, original activity recognition project is simply better to use for its outstanding simplicity. \n",
    "\n",
    "If you want to learn more about deep learning, I have also built a list of the learning ressources for deep learning which have revealed to be the most useful to me [here](https://github.com/guillaume-chevalier/Awesome-Deep-Learning-Resources). \n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "The [dataset](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) can be found on the UCI Machine Learning Repository: \n",
    "\n",
    "> Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.\n",
    "\n",
    "## Citation\n",
    "\n",
    "Copyright (c) 2016 Guillaume Chevalier. To cite my code, you can point to the URL of the GitHub repository, for example: \n",
    "\n",
    "> Guillaume Chevalier, LSTMs for Human Activity Recognition, 2016, \n",
    "> https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition\n",
    "\n",
    "My code is available for free and even for private usage for anyone under the [MIT License](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/blob/master/LICENSE), however I ask to cite for using the code. \n",
    "\n",
    "Here is the BibTeX citation code: \n",
    "```\n",
    "@misc{chevalier2016lstms,\n",
    "  title={LSTMs for human activity recognition},\n",
    "  author={Chevalier, Guillaume},\n",
    "  year={2016}\n",
    "}\n",
    "```\n",
    "\n",
    "## Extra links\n",
    "\n",
    "### Connect with me\n",
    "\n",
    "- [LinkedIn](https://ca.linkedin.com/in/chevalierg)\n",
    "- [Twitter](https://twitter.com/guillaume_che)\n",
    "- [GitHub](https://github.com/guillaume-chevalier/)\n",
    "- [Quora](https://www.quora.com/profile/Guillaume-Chevalier-2)\n",
    "- [YouTube](https://www.youtube.com/c/GuillaumeChevalier)\n",
    "- [Dev/Consulting](http://www.neuraxio.com/en/)\n",
    "\n",
    "### Liked this project? Did it help you? Leave a [star](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/stargazers), [fork](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/network/members) and share the love!\n",
    "\n",
    "This activity recognition project has been seen in:\n",
    "\n",
    "- [Hacker News 1st page](https://news.ycombinator.com/item?id=13049143)\n",
    "- [Awesome TensorFlow](https://github.com/jtoy/awesome-tensorflow#tutorials)\n",
    "- [TensorFlow World](https://github.com/astorfi/TensorFlow-World#some-useful-tutorials)\n",
    "- And more.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's convert this notebook to a README automatically for the GitHub project's title page:\n",
    "!jupyter nbconvert --to markdown LSTM.ipynb\n",
    "!mv LSTM.md README.md"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
