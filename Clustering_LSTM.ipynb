{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329c2b38-f844-45b7-b355-e6b3d0ca2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a3416a-de30-4bd6-a34a-ca10b3268d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvcc'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897026f0-0187-4621-b0fe-ff20957f37d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep  6 21:45:15 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 475.14       Driver Version: 475.14       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 N/A |                  N/A |\n",
      "| 33%    0C    P8    N/A /  N/A |    258MiB /  1024MiB |     N/A      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc33f63a-9326-46b8-bfe4-68870b29f640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47103fdb-63ad-47fc-918d-cb128ecacb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEE\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\cuda\\__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 1. 자이로스코프 데이터 로드 및 전처리\n",
    "data = pd.read_csv('./원본 데이터/자이로 데이터.csv')\n",
    "\n",
    "# 결측값 보간 처리\n",
    "data['X'] = data['X'].interpolate()\n",
    "data['Y'] = data['Y'].interpolate()\n",
    "data['Z'] = data['Z'].interpolate()\n",
    "\n",
    "# 2. 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "gyro_data = scaler.fit_transform(data[['X', 'Y', 'Z']])\n",
    "\n",
    "# 3. K-Means 클러스터링 적용\n",
    "num_clusters = 6\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "data['cluster'] = kmeans.fit_predict(gyro_data)\n",
    "\n",
    "# 슬라이딩 윈도우 함수 정의\n",
    "def sliding_window(data, window_size, step_size):\n",
    "    return [data[i:i + window_size] for i in range(0, len(data) - window_size + 1, step_size)]\n",
    "\n",
    "sequence_length = 128\n",
    "step_size = 10\n",
    "\n",
    "# 4. 슬라이딩 윈도우 적용 (입력 시퀀스 생성)\n",
    "gyro_sequences = sliding_window(gyro_data, sequence_length, step_size)\n",
    "gyro_sequences = np.array(gyro_sequences)\n",
    "\n",
    "# 클러스터 라벨도 슬라이딩 윈도우 적용\n",
    "cluster_labels = sliding_window(data['cluster'].values, sequence_length, step_size)\n",
    "cluster_labels = np.array(cluster_labels)\n",
    "\n",
    "# 5. 데이터를 훈련용과 검증용으로 나누기 (80% 훈련, 20% 검증)\n",
    "X_train, X_val, y_train, y_val = train_test_split(gyro_sequences, cluster_labels[:, 0], test_size=0.2, random_state=42)\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 텐서로 변환 및 GPU로 이동\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffdf655-ee2a-48c5-9ea3-d56dce206808",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 103\u001b[0m\n\u001b[0;32m    100\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m    101\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m  \u001b[38;5;66;03m# 배치 크기 설정\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 82\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, y_train, X_val, y_val, criterion, optimizer, num_epochs, batch_size)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# hidden state를 detach하여 그래프와의 연결을 끊음\u001b[39;00m\n\u001b[0;32m     80\u001b[0m hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([h\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hidden])\n\u001b[1;32m---> 82\u001b[0m outputs, hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[0;32m     84\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[1;32m---> 11\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# 마지막 시퀀스의 출력만 사용\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out, hidden\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:917\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6. LSTM 모델 정의\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])  # 마지막 시퀀스의 출력만 사용\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return (h_0, c_0)\n",
    "\n",
    "# 모델 및 학습 설정\n",
    "input_size = 3  # 자이로스코프 3축 데이터\n",
    "hidden_size = 64  # LSTM hidden layer 크기\n",
    "output_size = 6  # 예측 클래스 수 (K-means 클러스터 수)\n",
    "num_layers = 1  # LSTM 레이어 수\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 7. 검증 데이터 배치 처리 함수 정의\n",
    "def evaluate_model(model, X_val, y_val, criterion, batch_size):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, X_val.size(0), batch_size):\n",
    "            batch_X_val = X_val[i:i + batch_size]\n",
    "            batch_y_val = y_val[i:i + batch_size]\n",
    "\n",
    "            # 배치 크기 확인 후 hidden state 초기화\n",
    "            current_batch_size = batch_X_val.size(0)\n",
    "            hidden = model.init_hidden(current_batch_size)  # 배치 크기에 맞게 hidden state 초기화\n",
    "\n",
    "            outputs, hidden = model(batch_X_val, hidden)\n",
    "            loss = criterion(outputs, batch_y_val)\n",
    "            val_loss += loss.item()\n",
    "            predicted_classes = torch.argmax(outputs, dim=1)\n",
    "            val_correct += (predicted_classes == batch_y_val).sum().item()\n",
    "            val_total += batch_y_val.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    avg_val_loss = val_loss / val_total\n",
    "    return avg_val_loss, val_accuracy\n",
    "\n",
    "# 8. 모델 훈련 함수 정의\n",
    "def train_model(model, X_train, y_train, X_val, y_val, criterion, optimizer, num_epochs, batch_size):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        permutation = torch.randperm(X_train.size(0))\n",
    "        epoch_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        # 배치별로 훈련\n",
    "        for i in range(0, X_train.size(0), batch_size):\n",
    "            indices = permutation[i:i + batch_size]\n",
    "            batch_X, batch_y = X_train[indices], y_train[indices]\n",
    "\n",
    "            # 배치 크기 확인 후 hidden state 초기화\n",
    "            current_batch_size = batch_X.size(0)\n",
    "            hidden = model.init_hidden(current_batch_size)  # 배치 크기에 맞게 hidden state 초기화\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # hidden state를 detach하여 그래프와의 연결을 끊음\n",
    "            hidden = tuple([h.detach() for h in hidden])\n",
    "\n",
    "            outputs, hidden = model(batch_X, hidden)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            predicted_classes = torch.argmax(outputs, dim=1)\n",
    "            correct_predictions += (predicted_classes == batch_y).sum().item()\n",
    "            total_predictions += batch_y.size(0)\n",
    "\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(X_train):.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # 검증 데이터에 대한 평가\n",
    "        val_loss, val_accuracy = evaluate_model(model, X_val, y_val, criterion, batch_size)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# 9. 모델 학습 시작\n",
    "num_epochs = 50\n",
    "batch_size = 32  # 배치 크기 설정\n",
    "\n",
    "train_model(model, X_train, y_train, X_val, y_val, criterion, optimizer, num_epochs, batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72a85c-050a-4186-9965-adb305f00438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 예측된 행동 라벨로 변환 및 시각화\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions, _ = model(X_val, model.init_hidden(batch_size))\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "\n",
    "LABELS = [\"WALKING\", \"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\", \"SITTING\", \"STANDING\", \"LAYING\"]\n",
    "predicted_labels = [LABELS[class_idx] for class_idx in predicted_classes.cpu().numpy()]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(predicted_classes.cpu().numpy(), bins=np.arange(len(LABELS) + 1) - 0.5, rwidth=0.8)\n",
    "plt.title('Predicted Class Distribution (Validation)')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(np.arange(len(LABELS)), LABELS)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
