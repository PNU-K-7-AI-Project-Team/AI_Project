{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891bfea9-ba5e-4a4a-bd02-369cdac56302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def parse_end(s):\n",
    "    try:\n",
    "        return float(s[-1])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def read_data(file_path):\n",
    "    labels = {'Walking': 0, 'Jogging': 1, 'Upstairs': 2, 'Sitting': 3, 'Downstairs': 4, 'Standing': 5}    \n",
    "    data = np.loadtxt(file_path, delimiter=\",\", usecols=(0,1, 3, 4, 5),\n",
    "                      converters={1: lambda name: labels[name.decode()],\n",
    "                                  5: parse_end})\n",
    "    data = data[~np.isnan(data).any(axis=1)]\n",
    "    return data\n",
    "\n",
    "data = read_data(\"./DATA/WISDM_ar_v1.1/WISDM_ar_v1.1_raw.csv\")\n",
    "\n",
    "mean = np.mean(data[:,2:], axis=0)\n",
    "std = np.std(data[:,2:], axis=0)\n",
    "data[:,2:] = (data[:,2:]-mean)/std\n",
    "\n",
    "# 데이터 불균형 확인 및 시각화\n",
    "activity_counts = np.bincount(data[:, 1].astype(int))\n",
    "activity_names = ['Walking', 'Jogging', 'Upstairs', 'Sitting', 'Downstairs', 'Standing']\n",
    "\n",
    "print(\"활동별 데이터 수:\")\n",
    "for i, count in enumerate(activity_counts):\n",
    "    print(f\"{activity_names[i]}: {count}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(activity_names, activity_counts)\n",
    "plt.title(\"활동별 데이터 분포\")\n",
    "plt.xlabel(\"활동\")\n",
    "plt.ylabel(\"데이터 수\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 데이터 증강 함수\n",
    "def time_warp(x, sigma=0.2, knot=4):\n",
    "    orig_steps = np.arange(x.shape[0])\n",
    "    random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2, x.shape[1]))\n",
    "    warp_steps = np.zeros((knot+2, x.shape[1]))\n",
    "    warp_steps[0] = 0\n",
    "    warp_steps[-1] = x.shape[0] - 1\n",
    "    warp_steps[1:-1] = np.sort(np.random.randint(1, x.shape[0]-1, size=(knot, x.shape[1])))\n",
    "    warper = interp1d(warp_steps, random_warps, axis=0, bounds_error=False, fill_value='extrapolate')\n",
    "    warped_steps = warper(orig_steps)\n",
    "    return np.array([np.interp(orig_steps, warped_steps[:, i], x[:, i]) for i in range(x.shape[1])]).T\n",
    "\n",
    "def magnitude_warp(x, sigma=0.2, knot=4):\n",
    "    orig_steps = np.arange(x.shape[0])\n",
    "    random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2, x.shape[1]))\n",
    "    warp_steps = np.zeros((knot+2, x.shape[1]))\n",
    "    warp_steps[0] = 0\n",
    "    warp_steps[-1] = x.shape[0] - 1\n",
    "    warp_steps[1:-1] = np.sort(np.random.randint(1, x.shape[0]-1, size=(knot, x.shape[1])))\n",
    "    warper = interp1d(warp_steps, random_warps, axis=0, bounds_error=False, fill_value='extrapolate')\n",
    "    warped_steps = warper(orig_steps)\n",
    "    return x * warped_steps\n",
    "\n",
    "def window_slice(x, reduce_ratio=0.9):\n",
    "    target_len = int(reduce_ratio * x.shape[0])\n",
    "    if target_len >= x.shape[0]:\n",
    "        return x\n",
    "    starts = np.random.randint(low=0, high=x.shape[0] - target_len, size=(1,)).astype(int)[0]\n",
    "    return x[starts:starts + target_len]\n",
    "\n",
    "def window_warp(x, window_ratio=0.1, scales=[0.5, 2.]):\n",
    "    warp_scales = np.random.choice(scales, x.shape[1])\n",
    "    warp_size = np.ceil(window_ratio * x.shape[0]).astype(int)\n",
    "    window_steps = np.arange(warp_size)\n",
    "        \n",
    "    window_starts = np.random.randint(low=1, high=x.shape[0] - warp_size - 1, size=(x.shape[1])).astype(int)\n",
    "    window_ends = (window_starts + warp_size).astype(int)\n",
    "        \n",
    "    ret = np.zeros_like(x)\n",
    "    for i, pat in enumerate(x.T):\n",
    "        start_seg = pat[:window_starts[i]]\n",
    "        window_seg = np.interp(np.linspace(0, warp_size, num=int(warp_size*warp_scales[i])), window_steps, pat[window_starts[i]:window_ends[i]])\n",
    "        end_seg = pat[window_ends[i]:]\n",
    "        warped = np.concatenate((start_seg, window_seg, end_seg))                \n",
    "        ret[:, i] = np.interp(np.arange(x.shape[0]), np.linspace(0, x.shape[0], num=warped.size), warped).T\n",
    "    return ret\n",
    "\n",
    "def augment_data(x, y):\n",
    "    augmented_x = []\n",
    "    augmented_y = []\n",
    "    for i in range(len(x)):\n",
    "        augmented_x.append(x[i])\n",
    "        augmented_y.append(y[i])\n",
    "        \n",
    "        # Time warping\n",
    "        warped = time_warp(x[i])\n",
    "        augmented_x.append(warped)\n",
    "        augmented_y.append(y[i])\n",
    "        \n",
    "        # Magnitude warping\n",
    "        warped = magnitude_warp(x[i])\n",
    "        augmented_x.append(warped)\n",
    "        augmented_y.append(y[i])\n",
    "        \n",
    "        # Window slicing\n",
    "        sliced = window_slice(x[i])\n",
    "        if len(sliced) == len(x[i]):\n",
    "            augmented_x.append(sliced)\n",
    "            augmented_y.append(y[i])\n",
    "        \n",
    "        # Window warping\n",
    "        warped = window_warp(x[i])\n",
    "        augmented_x.append(warped)\n",
    "        augmented_y.append(y[i])\n",
    "    \n",
    "    return np.array(augmented_x), np.array(augmented_y)\n",
    "\n",
    "# 데이터 분할 및 세그먼트화\n",
    "x_train = data[data[:,0] <= 28]\n",
    "x_test = data[data[:,0] > 28]\n",
    "\n",
    "TIME_PERIODS = 80\n",
    "STEP_DISTANCE = 40\n",
    "\n",
    "def data_segments(data):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(data) - TIME_PERIODS, STEP_DISTANCE):\n",
    "        X = data[i:i+TIME_PERIODS, 2:].tolist()\n",
    "        values, counts = np.unique(data[i:i+TIME_PERIODS, 1], return_counts=True)\n",
    "        label = values[np.argmax(counts)]\n",
    "        segments.append(X)\n",
    "        labels.append(label)\n",
    "    segments = np.array(segments, dtype=np.float32).reshape(-1, TIME_PERIODS, 3)\n",
    "    labels = np.asarray(labels)\n",
    "    return segments, labels\n",
    "\n",
    "x_train, y_train = data_segments(x_train)\n",
    "x_test, y_test = data_segments(x_test)\n",
    "\n",
    "# 데이터 증강 적용\n",
    "x_train, y_train = augment_data(x_train, y_train)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_reshaped = x_train.reshape(x_train.shape[0], -1)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_reshaped, y_train)\n",
    "x_train = x_train_resampled.reshape(-1, TIME_PERIODS, 3)\n",
    "y_train = y_train_resampled\n",
    "\n",
    "# 원-핫 인코딩\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# 모델 구축\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(TIME_PERIODS, 3)),\n",
    "    tf.keras.layers.Conv1D(filters=100, kernel_size=11, activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv1D(filters=10, kernel_size=5, activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 모델 컴파일 및 훈련\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "ret = model.fit(x_train, y_train, epochs=100, batch_size=400,\n",
    "                validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "# 모델 평가\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=2)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# 정확도 및 손실 그래프\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(ret.history['accuracy'], label='train accuracy')\n",
    "plt.plot(ret.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(ret.history['loss'], label='train loss')\n",
    "plt.plot(ret.history['val_loss'], label='val loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 혼동 행렬 및 분류 보고서\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred_classes))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=activity_names))\n",
    "\n",
    "# 샘플 활동 시각화\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(6):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    activity_data = x_test[y_true == i][0]\n",
    "    plt.plot(activity_data)\n",
    "    plt.title(activity_names[i])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Normalized Acceleration')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
