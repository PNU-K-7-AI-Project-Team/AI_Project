{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1216f849-beb0-4f3b-928f-fad2be861b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86cdf4d6-33d9-4fe6-9ff2-dc2f94896201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:3: DtypeWarning: Columns (11,14,19,22,25,70,73,86,87,89,90,94,97,100) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_x_mean'] = features['gyros_forearm_x'].mean(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_y_mean'] = features['gyros_forearm_y'].mean(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_z_mean'] = features['gyros_forearm_z'].mean(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_x_std'] = features['gyros_forearm_x'].std(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_y_std'] = features['gyros_forearm_y'].std(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_z_std'] = features['gyros_forearm_z'].std(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_x_max'] = features['gyros_forearm_x'].max(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_y_max'] = features['gyros_forearm_y'].max(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_z_max'] = features['gyros_forearm_z'].max(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_x_min'] = features['gyros_forearm_x'].min(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_y_min'] = features['gyros_forearm_y'].min(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_z_min'] = features['gyros_forearm_z'].min(axis=0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_x_ma'] = features['gyros_forearm_x'].rolling(window=window_size).mean().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_y_ma'] = features['gyros_forearm_y'].rolling(window=window_size).mean().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_z_ma'] = features['gyros_forearm_z'].rolling(window=window_size).mean().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_x_roc'] = features['gyros_forearm_x'].pct_change().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_y_roc'] = features['gyros_forearm_y'].pct_change().fillna(0)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19416\\2429214835.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['gyros_forearm_z_roc'] = features['gyros_forearm_z'].pct_change().fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 및 전처리 함수\n",
    "def load_and_preprocess_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # 필요한 특징 선택\n",
    "    features = data[['gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z']]\n",
    "    labels = data['classe']\n",
    "\n",
    "    # 기본 통계량 특징 추가 (각 행별로 계산)\n",
    "    features['gyros_forearm_x_mean'] = features['gyros_forearm_x'].mean(axis=0)\n",
    "    features['gyros_forearm_y_mean'] = features['gyros_forearm_y'].mean(axis=0)\n",
    "    features['gyros_forearm_z_mean'] = features['gyros_forearm_z'].mean(axis=0)\n",
    "    \n",
    "    features['gyros_forearm_x_std'] = features['gyros_forearm_x'].std(axis=0)\n",
    "    features['gyros_forearm_y_std'] = features['gyros_forearm_y'].std(axis=0)\n",
    "    features['gyros_forearm_z_std'] = features['gyros_forearm_z'].std(axis=0)\n",
    "    \n",
    "    features['gyros_forearm_x_max'] = features['gyros_forearm_x'].max(axis=0)\n",
    "    features['gyros_forearm_y_max'] = features['gyros_forearm_y'].max(axis=0)\n",
    "    features['gyros_forearm_z_max'] = features['gyros_forearm_z'].max(axis=0)\n",
    "    \n",
    "    features['gyros_forearm_x_min'] = features['gyros_forearm_x'].min(axis=0)\n",
    "    features['gyros_forearm_y_min'] = features['gyros_forearm_y'].min(axis=0)\n",
    "    features['gyros_forearm_z_min'] = features['gyros_forearm_z'].min(axis=0)\n",
    "\n",
    "    # 이동 평균 추가\n",
    "    window_size = 5\n",
    "    features['gyros_forearm_x_ma'] = features['gyros_forearm_x'].rolling(window=window_size).mean().fillna(0)\n",
    "    features['gyros_forearm_y_ma'] = features['gyros_forearm_y'].rolling(window=window_size).mean().fillna(0)\n",
    "    features['gyros_forearm_z_ma'] = features['gyros_forearm_z'].rolling(window=window_size).mean().fillna(0)\n",
    "\n",
    "    # 변화율 특징 추가\n",
    "    features['gyros_forearm_x_roc'] = features['gyros_forearm_x'].pct_change().fillna(0)\n",
    "    features['gyros_forearm_y_roc'] = features['gyros_forearm_y'].pct_change().fillna(0)\n",
    "    features['gyros_forearm_z_roc'] = features['gyros_forearm_z'].pct_change().fillna(0)\n",
    "\n",
    "    # 결측값 및 inf 값 처리\n",
    "    features = features.replace([np.inf, -np.inf], np.nan)\n",
    "    features = features.fillna(0)\n",
    "\n",
    "    # 클래스 레이블 인코딩\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "# 데이터 로드\n",
    "training_data_path = './원본 데이터/pml-training.csv'\n",
    "features, labels = load_and_preprocess_data(training_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fb5163-1631-4a19-9399-a7ccdcf8db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 표준화\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# PyTorch TensorDataset 생성\n",
    "train_dataset = TensorDataset(torch.tensor(x_train).float(), torch.tensor(y_train).long())\n",
    "test_dataset = TensorDataset(torch.tensor(x_test).float(), torch.tensor(y_test).long())\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b96fcd1-4e0c-430f-82ad-bd9e7b8b2a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=1, stride=1)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        \n",
    "        x = x[:, -1, :]  # Use the output from the last LSTM\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220f229b-e0ab-4888-bf6e-c0c5df72b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "input_channels = 21  # 실제 입력 데이터의 채널 수를 21로 고정\n",
    "model = CNN_LSTM(input_channels=input_channels, num_classes=6)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fbaeac-d00b-4bd8-a0b8-dde8ad8cd364",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 64, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch_size, 1, features)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (batch_size, 1, features) -> (batch_size, features, 1)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m, in \u001b[0;36mCNN_LSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[1;32m---> 20\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     22\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm2(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:898\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    894\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[0;32m    895\u001b[0m                           max_batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size,\n\u001b[0;32m    896\u001b[0m                           dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    897\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[1;32m--> 898\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:827\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    823\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    824\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    825\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    826\u001b[0m                        ):\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    829\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    831\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:246\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 64, got 1"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, correct_train = 0, 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 입력 데이터의 차원을 확인하여 필요한 경우 3D로 변환\n",
    "        if inputs.dim() == 2:  # inputs의 차원이 (batch_size, features)인 경우\n",
    "            inputs = inputs.unsqueeze(1)  # (batch_size, 1, features)\n",
    "\n",
    "        inputs = inputs.transpose(1, 2)  # (batch_size, 1, features) -> (batch_size, features, 1)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy = correct_train / len(train_loader.dataset)\n",
    "\n",
    "    # 검증 루프\n",
    "    model.eval()\n",
    "    test_loss, correct_test = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            if inputs.dim() == 2:\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "                \n",
    "            inputs = inputs.transpose(1, 2)  # (batch_size, features, 1) -> (batch_size, 1, features)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = correct_test / len(test_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "          f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b09b7-fa5e-4650-9d0a-e57135f5ce41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
