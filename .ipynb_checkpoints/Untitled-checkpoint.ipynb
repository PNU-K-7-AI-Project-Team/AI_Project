{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986b6683-8d4b-452c-999b-7d3600486bcb",
   "metadata": {},
   "source": [
    "> UCI-HAR와 자이로 데이터 간의 차이를 줄이고, 자이로 데이터에 적합한 행동 라벨링을 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada6549-69b7-49a6-b716-143ccd015520",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 및 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec6ef79-f095-4874-a7b3-abbde581675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라이브러리 및 데이터셋 로드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.signal import butter, filtfilt, resample\n",
    "\n",
    "# GPU 사용 여부 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038b78be-c034-4b00-b7dd-da7c49f23981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb51601-77a7-425f-86dd-2afdc0e62774",
   "metadata": {},
   "source": [
    "### 1. 저역통과 필터 및 데이터 전처리 함수 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b692459-a690-4403-85cb-ac5ca704d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저역통과 필터 적용\n",
    "def butter_lowpass(cutoff, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def apply_lowpass_filter(data, cutoff=20, fs=50):\n",
    "    b, a = butter_lowpass(cutoff, fs)\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "# 데이터 정규화 및 차원 맞춤 함수\n",
    "def normalize_and_reshape_segments(segments):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_segments = np.zeros_like(segments)\n",
    "    for axis in range(segments.shape[2]):\n",
    "        normalized_segments[:, :, axis] = scaler.fit_transform(segments[:, :, axis])\n",
    "    return normalized_segments\n",
    "\n",
    "# 슬라이딩 윈도우 생성 함수\n",
    "def create_sliding_windows(data, window_size=128, stride=64):\n",
    "    num_windows = (len(data) - window_size) // stride + 1\n",
    "    windows = np.array([data[i:i+window_size] for i in range(0, len(data) - window_size + 1, stride)])\n",
    "    return windows  # (num_windows, window_size, 3) 형태로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c255f570-ff03-405e-99be-48a07eeba80b",
   "metadata": {},
   "source": [
    "### 2. UCI-HAR 데이터 로드 및 자이로 데이터 전처리 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38683cf5-1585-4ada-838a-95e30cf91ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCI-HAR 데이터 로드\n",
    "def load_ucihar_data():\n",
    "    uci_har_path = './원본 데이터/UCI HAR Dataset/'\n",
    "    gyro_x_train = pd.read_csv(uci_har_path + 'train/Inertial Signals/body_gyro_x_train.txt', sep='\\s+', header=None).values\n",
    "    gyro_y_train = pd.read_csv(uci_har_path + 'train/Inertial Signals/body_gyro_y_train.txt', sep='\\s+', header=None).values\n",
    "    gyro_z_train = pd.read_csv(uci_har_path + 'train/Inertial Signals/body_gyro_z_train.txt', sep='\\s+', header=None).values\n",
    "    labels_train = pd.read_csv(uci_har_path + 'train/y_train.txt', sep='\\s+', header=None).values - 1\n",
    "    X_train = np.stack([gyro_x_train, gyro_y_train, gyro_z_train], axis=-1)\n",
    "    X_train_normalized = normalize_and_reshape_segments(X_train)\n",
    "    return X_train_normalized, labels_train\n",
    "\n",
    "X_train, y_train = load_ucihar_data()\n",
    "\n",
    "# 자이로 데이터 전처리 함수\n",
    "def preprocess_gyro_data(gyro_path, current_freq=100, desired_freq=50, window_size=128, stride=64):\n",
    "    gyro_data = pd.read_csv(gyro_path)\n",
    "    n_samples = int(len(gyro_data) * desired_freq / current_freq)\n",
    "    gyro_data_resampled = resample(gyro_data[['X', 'Y', 'Z']].values, n_samples)\n",
    "    gyro_data_filtered = apply_lowpass_filter(gyro_data_resampled, cutoff=20, fs=desired_freq)\n",
    "    gyro_data_windows = create_sliding_windows(gyro_data_filtered, window_size, stride)\n",
    "    gyro_data_normalized = normalize_and_reshape_segments(gyro_data_windows)\n",
    "    return torch.tensor(gyro_data_normalized, dtype=torch.float32)\n",
    "\n",
    "gyro_data_tensor = preprocess_gyro_data('./원본 데이터/자이로 데이터.csv')\n",
    "\n",
    "# 데이터를 Tensor로 변환\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "gyro_data_tensor = gyro_data_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caacb8c2-1abb-4da7-bf34-b2c9715a6ac7",
   "metadata": {},
   "source": [
    "### 3. 데이터 증강 및 불균형 해결 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16230532-a664-4583-8406-8c07e54762a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 함수: 가우시안 노이즈 추가\n",
    "def add_gaussian_noise(data, noise_factor=0.05):\n",
    "    noise = np.random.randn(*data.shape)\n",
    "    augmented_data = data + noise_factor * noise\n",
    "    augmented_data = np.clip(augmented_data, -1.0, 1.0)\n",
    "    return augmented_data\n",
    "\n",
    "def time_warp(data, sigma=0.2, knot=4):\n",
    "    orig_steps = np.arange(data.shape[1])\n",
    "    random_warps = np.random.normal(loc=1.0, scale=sigma, size=(data.shape[0], knot+2, data.shape[2]))\n",
    "    warp_steps = (np.ones((data.shape[2],1))*(np.linspace(0, data.shape[1]-1., num=knot+2))).T\n",
    "    ret = np.zeros_like(data)\n",
    "    for i, pat in enumerate(data):\n",
    "        warper = np.interp(orig_steps, warp_steps[:, 0], random_warps[i, :, 0])\n",
    "        for dim in range(data.shape[2]):\n",
    "            ret[i, :, dim] = np.interp(orig_steps, np.cumsum(warper), pat[:, dim])\n",
    "    return ret\n",
    "\n",
    "# 증강된 데이터 결합 및 불균형 데이터 해결\n",
    "X_train_augmented = add_gaussian_noise(X_train)\n",
    "\n",
    "# 증강된 데이터 결합\n",
    "X_train_augmented = np.concatenate([\n",
    "    X_train,\n",
    "    add_gaussian_noise(X_train),\n",
    "    time_warp(X_train)\n",
    "], axis=0)\n",
    "\n",
    "y_train_augmented = np.concatenate([y_train] * 3, axis=0)\n",
    "\n",
    "# 클래스별 샘플 수 계산\n",
    "class_sample_count = np.array([len(np.where(y_train_augmented == t)[0]) for t in np.unique(y_train_augmented)])\n",
    "\n",
    "# 길이 확인 및 조정\n",
    "min_length = min(len(X_train_augmented), len(y_train_augmented))\n",
    "X_train_augmented = X_train_augmented[:min_length]\n",
    "y_train_augmented = y_train_augmented[:min_length]\n",
    "\n",
    "# 텐서로 변환\n",
    "X_train_augmented_tensor = torch.tensor(X_train_augmented, dtype=torch.float32)\n",
    "y_train_augmented_tensor = torch.tensor(y_train_augmented, dtype=torch.long)\n",
    "\n",
    "# 학습/검증 데이터 분리\n",
    "X_train_tensor, X_val_tensor, y_train_tensor, y_val_tensor = train_test_split(\n",
    "    X_train_augmented_tensor, \n",
    "    y_train_augmented_tensor, \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f66a65-bfa7-44a0-ace2-918bdc495d51",
   "metadata": {},
   "source": [
    "### 4. 데이터셋 및 모델 정의 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18092f1-b7c1-48a4-8e10-a8a817b40926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스\n",
    "class UCIHARData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx].view(-1)\n",
    "    \n",
    "train_dataset = UCIHARData(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = UCIHARData(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba567f6-5e53-4da3-bf91-2be92ef4f88c",
   "metadata": {},
   "source": [
    "## 5. LSTM, GRU, CNN-LSTM, BiLSTM, Transformer 모델 정의 및 성능 개선(앙상블)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98fa2695-7fae-44c3-8b44-089e15fde875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 정의\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.input_size = input_size  # 추가\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.batch_norm(out[:, -1, :])\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# GRU 모델 정의\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.input_size = input_size  # 추가\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = self.batch_norm(out[:, -1, :])\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# CNN-LSTM 모델 정의\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "        self.input_size = input_size  # 추가\n",
    "        self.conv1 = nn.Conv1d(input_size, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.lstm = nn.LSTM(64, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# BiLSTM 모델 정의\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.input_size = input_size  # 추가\n",
    "        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob, bidirectional=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.bilstm(x)\n",
    "        out = self.batch_norm(out[:, -1, :])\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Transformer 모델 정의\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_heads, num_layers, num_classes, dropout_prob):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.input_size = input_size  # 추가\n",
    "        self.input_embedding = nn.Linear(input_size, 128)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, 200, 128))  # 시퀀스 길이가 100이라고 가정\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=num_heads, dropout=dropout_prob)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, input_size) -> (seq_len, batch_size, input_size)\n",
    "        x = self.input_embedding(x)\n",
    "        x = x + self.positional_encoding[:, :x.size(1), :]\n",
    "        x = self.transformer(x.permute(1, 0, 2))  # (seq_len, batch_size, d_model)\n",
    "        out = self.fc(x[-1, :, :])  # 마지막 타임스텝의 출력만 사용\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c7682c-24fa-402d-ab3a-6b4b4bd2cb76",
   "metadata": {},
   "source": [
    "## 6. 앙상블 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ab5040-8752-4085-8c10-735abab8b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 3\n",
      "Model 1 input size: 3\n",
      "Model 2 input size: 3\n",
      "Model 3 input size: 3\n",
      "Model 4 input size: 3\n",
      "Model 5 input size: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# 입력 크기 정의\n",
    "input_size = 3  # X, Y, Z 축\n",
    "\n",
    "# 모델 정의\n",
    "models = [\n",
    "    LSTMModel(input_size=input_size, hidden_size=128, num_layers=3, num_classes=6, dropout_prob=0.7).to(device),\n",
    "    GRUModel(input_size=input_size, hidden_size=128, num_layers=3, num_classes=6, dropout_prob=0.7).to(device),\n",
    "    CNNLSTMModel(input_size=input_size, hidden_size=128, num_layers=3, num_classes=6, dropout_prob=0.7).to(device),\n",
    "    BiLSTMModel(input_size=input_size, hidden_size=128, num_layers=3, num_classes=6, dropout_prob=0.7).to(device),\n",
    "    TransformerModel(input_size=input_size, num_heads=4, num_layers=2, num_classes=6, dropout_prob=0.7).to(device)\n",
    "]\n",
    "\n",
    "# 입력 크기 확인\n",
    "print(f\"Input size: {input_size}\")\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1} input size: {model.input_size if hasattr(model, 'input_size') else 'N/A'}\")\n",
    "\n",
    "# 모델들의 예측값을 앙상블로 처리\n",
    "# 앙상블 예측 함수\n",
    "def ensemble_predict(models, X_unlabeled, weights=[1, 1, 1, 1, 1]):\n",
    "    predictions = []\n",
    "    X_unlabeled = X_unlabeled.to(device)\n",
    "    for i, model in enumerate(models):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_unlabeled)\n",
    "            predictions.append(weights[i] * torch.softmax(outputs, dim=1))\n",
    "    \n",
    "    final_predictions = torch.argmax(sum(predictions), dim=1)\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c17d8-8100-4c69-8a9e-9d0e9c4a11b0",
   "metadata": {},
   "source": [
    "## 7. 손실 함수, 옵티마이저, 스케줄러 및 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909ee838-0a4f-4a46-8a69-f5973facad92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# 클래스별 가중치 계산\n",
    "class_weights = 1.0 / torch.tensor(class_sample_count, dtype=torch.float32)\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "# 손실 함수 정의 (가중치 적용)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# 각 모델별로 옵티마이저와 스케줄러 정의\n",
    "optimizers = [\n",
    "    torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4) for model in models\n",
    "]\n",
    "\n",
    "schedulers = [\n",
    "    torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0.0001) for optimizer in optimizers\n",
    "]\n",
    "\n",
    "# 모델 저장 함수\n",
    "def save_checkpoint(epoch, model, optimizer, filename=\"checkpoint.pth.tar\"):\n",
    "    state = {'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "    torch.save(state, filename)\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_model(models, train_loader, val_loader, criterion, optimizers, schedulers, num_epochs=30, patience=20):\n",
    "    global best_val_accuracy\n",
    "    early_stop_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for model in models:\n",
    "            model.train()\n",
    "        \n",
    "        running_loss = [0.0] * len(models)\n",
    "        correct = [0] * len(models)\n",
    "        total = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "           # 수정 코드\n",
    "            labels = labels.to(device).squeeze()  # 1D로 변환\n",
    "            print(f\"Labels shape: {labels.shape}\")\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # 각 모델별 학습\n",
    "            for j, model in enumerate(models):\n",
    "                optimizers[j].zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # 그래디언트 클리핑 추가\n",
    "                optimizers[j].step()\n",
    "                \n",
    "                running_loss[j] += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct[j] += (predicted.cpu() == labels.cpu()).sum().item()\n",
    "\n",
    "        # Training accuracy and loss\n",
    "        for j, model in enumerate(models):\n",
    "            accuracy = 100 * correct[j] / total\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Model {j+1} Training Loss: {running_loss[j]/len(train_loader):.4f}, Training Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        # Validation loop\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "        \n",
    "        val_loss = [0.0] * len(models)\n",
    "        val_correct = [0] * len(models)\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                # 수정 코드\n",
    "                labels = labels.to(device).squeeze()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                for j, model in enumerate(models):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss[j] += loss.item()\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_correct[j] += (predicted.cpu() == labels.cpu()).sum().item()\n",
    "\n",
    "        # Validation accuracy and loss\n",
    "        for j, model in enumerate(models):\n",
    "            val_accuracy = (val_correct[j] / val_total) * 100\n",
    "            val_loss[j] = val_loss[j] / len(val_loader)\n",
    "\n",
    "            print(f\"Model {j+1} Validation Accuracy: {val_accuracy:.2f}%, Validation Loss: {val_loss[j]:.4f}\")\n",
    "\n",
    "            # 스케줄러 갱신\n",
    "            schedulers[j].step()\n",
    "\n",
    "            # Save best model\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                save_checkpoint(epoch, model, optimizers[j], filename=f\"best_model_{j+1}.pth.tar\")\n",
    "                print(f\"Best model {j+1} saved with accuracy: {best_val_accuracy:.2f}%\")\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# 모델 학습 실행\n",
    "train_model(models, train_loader, val_loader, criterion, optimizers, schedulers, num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ffcde-3ec3-4776-92b9-cc004933b884",
   "metadata": {},
   "source": [
    "## 8. 슬라이딩 윈도우와 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f6b35-b35d-4ca7-9adf-1b3f540d83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 로드\n",
    "for i, model in enumerate(models):\n",
    "    checkpoint = torch.load(f'best_model_{i+1}.pth.tar')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "# 자이로 데이터를 GPU로 이동\n",
    "gyro_data_tensor = gyro_data_tensor.to(device)\n",
    "\n",
    "print(f\"gyro_data_tensor shape: {gyro_data_tensor.shape}\")\n",
    "\n",
    "# 예측\n",
    "batch_size = 100\n",
    "all_predictions = []\n",
    "\n",
    "for i in range(0, len(gyro_data_tensor), batch_size):\n",
    "    batch = gyro_data_tensor[i:i+batch_size]\n",
    "    # 마지막 배치 처리\n",
    "    if len(batch) < batch_size:\n",
    "        padding = torch.zeros(batch_size - len(batch), *batch.shape[1:], device=device)\n",
    "        batch = torch.cat([batch, padding], dim=0)\n",
    "    print(f\"Batch shape: {batch.shape}\")  # 디버깅용\n",
    "    batch_predictions = ensemble_predict(models, batch)\n",
    "    # 패딩 제거\n",
    "    all_predictions.append(batch_predictions[:len(gyro_data_tensor[i:i+batch_size])])\n",
    "\n",
    "all_predictions = torch.cat(all_predictions).cpu().numpy()\n",
    "\n",
    "# 슬라이딩 윈도우 예측 결과를 원본 데이터에 매핑하는 함수\n",
    "def map_predictions_to_original(original_data_length, predictions, window_size, stride):\n",
    "    mapped_predictions = np.zeros((original_data_length, 6))  # 6은 활동 클래스의 수\n",
    "    counts = np.zeros(original_data_length)\n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        start = i * stride\n",
    "        end = min(start + window_size, original_data_length)\n",
    "        mapped_predictions[start:end, pred] += 1\n",
    "        counts[start:end] += 1\n",
    "    \n",
    "    # 각 데이터 포인트에 대해 가장 많이 예측된 라벨 선택\n",
    "    final_predictions = np.argmax(mapped_predictions, axis=1)\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "# 원본 자이로 데이터 로드\n",
    "original_gyro_data = pd.read_csv('./원본 데이터/자이로 데이터.csv')\n",
    "\n",
    "# 원본 데이터에 맞는 예측 라벨 생성\n",
    "original_predictions = map_predictions_to_original(len(original_gyro_data), all_predictions, window_size=128, stride=64)\n",
    "\n",
    "# 예측된 라벨을 활동 이름으로 매핑\n",
    "activity_labels = {0: \"walking\", 1: \"walking_upstairs\", 2: \"walking_downstairs\", 3: \"sitting\", 4: \"standing\", 5: \"laying\"}\n",
    "predicted_activities = [activity_labels[label] for label in original_predictions]\n",
    "\n",
    "# 예측 결과 출력\n",
    "for i, activity in enumerate(predicted_activities[:10]):\n",
    "    print(f\"Sample {i}: {activity}\")\n",
    "\n",
    "# 자이로 데이터에 예측 결과 추가\n",
    "original_gyro_data['Predicted_Activity'] = predicted_activities\n",
    "\n",
    "# 결과 저장\n",
    "original_gyro_data.to_csv('./원본 데이터/자이로 데이터_예측.csv', index=False)\n",
    "\n",
    "# 예측 결과 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "activity_counts = pd.Series(predicted_activities).value_counts()\n",
    "sns.barplot(x=activity_counts.index, y=activity_counts.values)\n",
    "plt.title('Predicted Activity Distribution')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 시간에 따른 활동 변화 시각화\n",
    "plt.figure(figsize=(20, 6))\n",
    "activity_series = pd.Series(predicted_activities)\n",
    "activity_numeric = pd.factorize(activity_series)[0]\n",
    "plt.plot(activity_numeric)\n",
    "plt.title('Activity Changes Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Activity')\n",
    "plt.yticks(range(len(activity_labels)), list(activity_labels.values()))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"예측 완료 및 결과 저장됨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a38691-f8b2-4b16-aeba-9f04c24c1a15",
   "metadata": {},
   "source": [
    "## 9. 성능 평가 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ff3ec-f240-460e-a936-6e29681dd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자이로 데이터에 라벨 추가\n",
    "gyro_data = pd.read_csv('./원본 데이터/자이로 데이터.csv')\n",
    "gyro_data['Predicted_Activity'] = predicted_activities[:len(gyro_data)]  # 길이 맞춤\n",
    "\n",
    "# 라벨링된 자이로 데이터를 저장\n",
    "gyro_data.to_csv('./원본 데이터/자이로 데이터_예측.csv', index=False)\n",
    "\n",
    "# 예측된 활동별 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=gyro_data['Predicted_Activity'])\n",
    "plt.title('Predicted Activity Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 예측 결과 요약\n",
    "print(gyro_data['Predicted_Activity'].value_counts(normalize=True))\n",
    "\n",
    "# 클러스터링 적용 및 결과 비교\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(gyro_data_tensor.cpu().numpy().reshape(gyro_data_tensor.shape[0], -1))\n",
    "\n",
    "# 클러스터링 결과와 실제 예측 라벨 비교\n",
    "kmeans_accuracy = accuracy_score(all_predictions, kmeans_labels)\n",
    "print(f\"K-Means Clustering Accuracy: {kmeans_accuracy:.2f}\")\n",
    "\n",
    "# Confusion Matrix 및 성능 평가\n",
    "cm = confusion_matrix(all_predictions, kmeans_labels)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(all_predictions, kmeans_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d8032-d19b-4d55-9eea-e18b72700063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
