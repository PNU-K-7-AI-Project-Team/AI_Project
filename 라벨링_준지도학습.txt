> UCI-HAR와 자이로 데이터 간의 차이를 줄이고, 자이로 데이터에 적합한 행동 라벨링을 추가

## 1. 라이브러리 및 데이터셋 로드

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, f1_score
from sklearn.cluster import KMeans
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from imblearn.over_sampling import RandomOverSampler

# GPU 사용 여부 설정
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

## 2. UCI-HAR 데이터 로드 및 전처리

uci_har_path = './원본 데이터/UCI HAR Dataset/'

def load_ucihar_data():
    gyro_x_train_path = uci_har_path + 'train/Inertial Signals/body_gyro_x_train.txt'
    gyro_y_train_path = uci_har_path + 'train/Inertial Signals/body_gyro_y_train.txt'
    gyro_z_train_path = uci_har_path + 'train/Inertial Signals/body_gyro_z_train.txt'
    labels_train_path = uci_har_path + 'train/y_train.txt'
    
    gyro_x_train = pd.read_csv(gyro_x_train_path, sep='\s+', header=None).values
    gyro_y_train = pd.read_csv(gyro_y_train_path, sep='\s+', header=None).values
    gyro_z_train = pd.read_csv(gyro_z_train_path, sep='\s+', header=None).values
    labels_train = pd.read_csv(labels_train_path, sep='\s+', header=None).values - 1
    
    X_train = np.stack([gyro_x_train, gyro_y_train, gyro_z_train], axis=-1)
    return X_train, labels_train

X_train, y_train = load_ucihar_data()

# 축별 정규화: 각 축을 개별적으로 정규화
scaler = StandardScaler()
for i in range(X_train.shape[2]):
    X_train[:, :, i] = scaler.fit_transform(X_train[:, :, i])

X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.long).squeeze()

## 3. 데이터 증강 및 불균형 해결(SMOTE 적용)

def add_gaussian_noise(data, noise_factor=0.05):
    noise = np.random.randn(*data.shape)
    augmented_data = data + noise_factor * noise
    augmented_data = np.clip(augmented_data, -1.0, 1.0)
    return augmented_data

X_train_augmented = add_gaussian_noise(X_train)

# 증강된 데이터 결합
X_train_full = np.concatenate([X_train, X_train_augmented], axis=0)
y_train_full = np.concatenate([y_train, y_train], axis=0)

# 평면화 (2D 변환) 후 불균형 해결 (RandomOverSampler 사용)
X_train_flattened = X_train_full.reshape(X_train_full.shape[0], -1)
ros = RandomOverSampler(random_state=42)
X_train_res, y_train_res = ros.fit_resample(X_train_flattened, y_train_full)

# 시계열 형태로 복원 (3D)
X_train_res = X_train_res.reshape(-1, X_train.shape[1], X_train.shape[2])

# 텐서로 변환
X_train_res_tensor = torch.tensor(X_train_res, dtype=torch.float32)
y_train_res_tensor = torch.tensor(y_train_res, dtype=torch.long)

# 데이터셋 분리 (학습/검증 데이터)
X_train_tensor, X_val_tensor, y_train_tensor, y_val_tensor = train_test_split(X_train_res_tensor, 
                                                                              y_train_res_tensor, 
                                                                              test_size=0.2, 
                                                                              random_state=42)

## 4. 데이터셋 로더 생성

class UCIHARData(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# 데이터 로더 생성
train_dataset = UCIHARData(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

val_dataset = UCIHARData(X_val_tensor, y_val_tensor)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

## 5. LSTM, GRU, CNN-LSTM, BiLSTM, Transformer 모델 정의 및 성능 개선(앙상블)

# LSTM 모델 정의
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)
        self.batch_norm = nn.BatchNorm1d(hidden_size)
        self.dropout = nn.Dropout(dropout_prob)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.batch_norm(out[:, -1, :])
        out = self.dropout(out)
        out = self.fc(out)
        return out

# GRU 모델 정의
class GRUModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):
        super(GRUModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)
        self.batch_norm = nn.BatchNorm1d(hidden_size)
        self.dropout = nn.Dropout(dropout_prob)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out, _ = self.gru(x)
        out = self.batch_norm(out[:, -1, :])
        out = self.dropout(out)
        out = self.fc(out)
        return out

# CNN-LSTM 모델 정의
class CNNLSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):
        super(CNNLSTMModel, self).__init__()
        self.conv1 = nn.Conv1d(input_size, 64, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)
        self.lstm = nn.LSTM(64, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        x = x.permute(0, 2, 1)
        x = self.pool(F.relu(self.conv1(x)))
        x = x.permute(0, 2, 1)
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return out

# BiLSTM 모델 정의
class BiLSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):
        super(BiLSTMModel, self).__init__()
        self.bilstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob, bidirectional=True)
        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)
        self.dropout = nn.Dropout(dropout_prob)
        self.fc = nn.Linear(hidden_size * 2, num_classes)

    def forward(self, x):
        out, _ = self.bilstm(x)
        out = self.batch_norm(out[:, -1, :])
        out = self.dropout(out)
        out = self.fc(out)
        return out

# Transformer 모델 정의
class TransformerModel(nn.Module):
    def __init__(self, input_size, num_heads, num_layers, num_classes, dropout_prob):
        super(TransformerModel, self).__init__()
        self.input_embedding = nn.Linear(input_size, 128)
        self.positional_encoding = nn.Parameter(torch.randn(1, 200, 128))  # 시퀀스 길이가 100이라고 가정
        encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=num_heads, dropout=dropout_prob)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        self.fc = nn.Linear(128, num_classes)

    def forward(self, x):
        # x: (batch_size, seq_len, input_size) -> (seq_len, batch_size, input_size)
        x = self.input_embedding(x)
        x = x + self.positional_encoding[:, :x.size(1), :]
        x = self.transformer(x.permute(1, 0, 2))  # (seq_len, batch_size, d_model)
        out = self.fc(x[-1, :, :])  # 마지막 타임스텝의 출력만 사용
        return out


## 6. 앙상블 모델 정의

# 앙상블에 포함될 모델 리스트 정의
models = [
    LSTMModel(input_size=X_train.shape[2], hidden_size=128, num_layers=3, num_classes=6, dropout_prob=0.6).to(device),
    GRUModel(input_size=X_train.shape[2], hidden_size=128, num_layers=3, num_classes=6, dropout_prob=0.6).to(device),
    CNNLSTMModel(input_size=X_train.shape[2], hidden_size=128, num_layers=3, num_classes=6, dropout_prob=0.6).to(device),
    BiLSTMModel(input_size=X_train.shape[2], hidden_size=128, num_layers=3, num_classes=6, dropout_prob=0.6).to(device),
    TransformerModel(input_size=X_train.shape[2], num_heads=4, num_layers=2, num_classes=6, dropout_prob=0.6).to(device)
]

# 모델들의 예측값을 앙상블로 처리
# 가중 평균을 적용한 앙상블 예측
def ensemble_predict(models, X_unlabeled, weights=[1, 1, 1, 1, 1]):
    predictions = []
    for i, model in enumerate(models):
        model.eval()
        with torch.no_grad():
            outputs = model(X_unlabeled)
            predictions.append(weights[i] * torch.argmax(outputs, dim=1))
    
    final_predictions = torch.mode(torch.stack(predictions), dim=0)[0]
    return final_predictions


## 7. 손실 함수, 옵티마이저, 스케줄러 및 모델 학습

# 손실 함수 및 옵티마이저 정의
criterion = nn.CrossEntropyLoss()
# 각 모델별로 옵티마이저와 스케줄러 정의
optimizers = [
    torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4) for model in models
]

schedulers = [
    torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0.0001) for optimizer in optimizers
]

# 모델 저장 함수
def save_checkpoint(epoch, model, optimizer, filename="checkpoint.pth.tar"):
    state = {'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}
    torch.save(state, filename)

best_val_accuracy = 0.0

# 모델 학습 함수
def train_model(models, train_loader, val_loader, criterion, optimizers, schedulers, num_epochs=30, patience=5):
    global best_val_accuracy
    early_stop_counter = 0
    
    for epoch in range(num_epochs):
        for model in models:
            model.train()
        
        running_loss = [0.0] * len(models)
        correct = [0] * len(models)
        total = 0
        
        # Training loop
        for i, (inputs, labels) in enumerate(train_loader):
            inputs = inputs.to(device)
            labels = labels.to(device).squeeze()
            total += labels.size(0)

            # 각 모델별 학습
            for j, model in enumerate(models):
                optimizers[j].zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizers[j].step()
                
                running_loss[j] += loss.item()
                _, predicted = torch.max(outputs, 1)
                correct[j] += (predicted.cpu() == labels.cpu()).sum().item()

        # Training accuracy and loss
        for j, model in enumerate(models):
            accuracy = 100 * correct[j] / total
            print(f"Epoch [{epoch+1}/{num_epochs}], Model {j+1} Training Loss: {running_loss[j]/len(train_loader):.4f}, Training Accuracy: {accuracy:.2f}%")
        
        # Validation loop
        for model in models:
            model.eval()
        
        val_loss = [0.0] * len(models)
        val_correct = [0] * len(models)
        val_total = 0
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs = inputs.to(device)
                labels = labels.to(device).squeeze()
                val_total += labels.size(0)

                for j, model in enumerate(models):
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    val_loss[j] += loss.item()

                    _, predicted = torch.max(outputs, 1)
                    val_correct[j] += (predicted.cpu() == labels.cpu()).sum().item()

        # Validation accuracy and loss
        for j, model in enumerate(models):
            val_accuracy = (val_correct[j] / val_total) * 100
            val_loss[j] = val_loss[j] / len(val_loader)

            print(f"Model {j+1} Validation Accuracy: {val_accuracy:.2f}%, Validation Loss: {val_loss[j]:.4f}")

            # 스케줄러 갱신
            schedulers[j].step()

            # Save best model
            if val_accuracy > best_val_accuracy:
                best_val_accuracy = val_accuracy
                save_checkpoint(epoch, model, optimizers[j], filename=f"best_model_{j+1}.pth.tar")
                print(f"Best model {j+1} saved with accuracy: {best_val_accuracy:.2f}%")
                early_stop_counter = 0
            else:
                early_stop_counter += 1

        # Early stopping
        if early_stop_counter >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break

        torch.cuda.empty_cache()

# 모델 학습 실행
train_model(models, train_loader, val_loader, criterion, optimizers, schedulers, num_epochs=30)

## 8. 슬라이딩 윈도우와 예측

# 배치 단위로 슬라이딩 윈도우 적용하는 함수
def create_sliding_windows_batch(data, seq_len, batch_size):
    for start in range(0, len(data) - seq_len + 1, batch_size):
        end = min(start + batch_size, len(data) - seq_len + 1)
        sequences = [data[i:i + seq_len] for i in range(start, end)]
        yield np.array(sequences)

# 라벨 없는 데이터에 대해 시퀀스 길이 맞추기
seq_len = X_train.shape[1]
gyro_data = pd.read_csv('./원본 데이터/자이로 데이터.csv')
gyro_data_values = gyro_data[['X', 'Y', 'Z']].values
gyro_data_normalized = scaler.transform(gyro_data_values)

# 슬라이딩 윈도우 적용 및 예측에 사용할 데이터 크기 정의 (예: 1000개씩 처리)
chunk_size = 1000  # 한번에 처리할 데이터 크기

# 빈 리스트로 예측값 저장
all_predictions = []

# 슬라이딩 윈도우를 배치로 처리
for batch_sliding_windows in create_sliding_windows_batch(gyro_data_normalized, seq_len, chunk_size):
    # PyTorch 텐서로 변환
    batch_tensor = torch.tensor(batch_sliding_windows, dtype=torch.float32).to(device)
    
    # 모델 예측을 chunk_size만큼씩 처리
    with torch.no_grad():
        batch_predictions = ensemble_predict(models, batch_tensor)  # 각 배치에 대해 예측 수행
        all_predictions.append(batch_predictions)  # 예측 결과를 저장

# 최종 예측값을 하나의 텐서로 합침
all_predictions = torch.cat(all_predictions)

# 예측된 라벨을 활동 이름으로 매핑
activity_labels = {0: "walking", 1: "walking_upstairs", 2: "walking_downstairs", 3: "sitting", 4: "standing", 5: "laying"}
predicted_activities = [activity_labels[label.item()] for label in all_predictions]

# 예측 결과 출력
for i, activity in enumerate(predicted_activities[:10]):  # 예시로 10개의 결과만 출력
    print(f"Sample {i}: {activity}")

## 9. 성능 평가 및 시각화

# 예측 결과를 CSV 파일로 저장
gyro_data['Predicted_Activity'] = predicted_activities
gyro_data.to_csv('./원본 데이터/자이로 데이터_예측.csv', index=False)

# 예측된 활동별 분포 시각화
plt.figure(figsize=(10, 6))
sns.countplot(x=gyro_data['Predicted_Activity'])
plt.title('Predicted Activity Distribution')
plt.xticks(rotation=45)
plt.show()

# 클러스터링 적용
kmeans = KMeans(n_clusters=6, random_state=42)
kmeans_labels = kmeans.fit_predict(X_unlabeled.cpu().numpy())

# 클러스터링 결과와 실제 예측 라벨 비교
kmeans_accuracy = accuracy_score(predictions.cpu().numpy(), kmeans_labels)
print(f"K-Means Clustering Accuracy: {kmeans_accuracy:.2f}")

# 성능 분석: confusion matrix
cm = confusion_matrix(predictions.cpu().numpy(), kmeans_labels)
ConfusionMatrixDisplay(cm).plot()
plt.show()

print(classification_report(predictions.cpu().numpy(), kmeans_labels))

